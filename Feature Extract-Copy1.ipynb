{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage: function plotting will plot rmsd, rmsd histogram, rmsf and PCA projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import mdtraj as md\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.cluster.hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "import pandas as pd\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import MDAnalysis as mda\n",
    "#XRD Ensemble\n",
    "#28 4NPQ\n",
    "#18 4HFI\n",
    "residue_selection = 'resSeq 8 to 316'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_notes = ['5NJY_pH70_md1','5NJY_pH70_md2','5NJY_pH70_md3','5NJY_F238L_pH70_md1',\n",
    "                 '5NJY_F238L_pH70_md2','5NJY_F238L_pH70_md3','5NJY_I233T_pH70_md4',\n",
    "                  '5NJY_I233T_pH70_md2','5NJY_I233T_pH70_md3','5NJY_F238LI233T_pH70_md1',\n",
    "                  '5NJY_F238LI233T_pH70_md2','5NJY_F238LI233T_pH70_md3','5NJY_pH46_md1','5NJY_pH46_md2','5NJY_pH46_md3','5NJY_F238L_pH46_md1',\n",
    "                 '5NJY_F238L_pH46_md2','5NJY_F238L_pH46_md3','5NJY_I233T_pH46_md1',\n",
    "                  '5NJY_I233T_pH46_md2','5NJY_I233T_pH46_md3','5NJY_F238LI233T_pH46_md1',\n",
    "                  '5NJY_F238LI233T_pH46_md2','5NJY_F238LI233T_pH46_md3','4HFI_pH46_md1','4HFI_pH46_md2','4HFI_pH46_md3','4HFI_F238L_pH46_md1',\n",
    "                 '4HFI_F238L_pH46_md2','4HFI_F238L_pH46_md3','4HFI_I233T_pH46_md1',\n",
    "                  '4HFI_I233T_pH46_md2','4HFI_I233T_pH46_md3','4HFI_F238LI233T_pH46_md1',\n",
    "                  '4HFI_F238LI233T_pH46_md2','4HFI_F238LI233T_pH46_md3','4NPQ_pH70_md5','4NPQ_pH70_md6','4NPQ_pH70_md7','4NPQ_F238L_pH70_md3',\n",
    "                 '4NPQ_F238L_pH70_md4','4NPQ_F238L_pH70_md5','4NPQ_I233T_pH70_md3',\n",
    "                  '4NPQ_I233T_pH70_md4','4NPQ_I233T_pH70_md5','4NPQ_F238LI233T_pH70_md3',\n",
    "                  '4NPQ_F238LI233T_pH70_md4','4NPQ_F238LI233T_pH70_md5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Notations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_md_dataframe():    \n",
    "    md_data = pd.DataFrame(columns=list(['MD_name','pH','replicate','traj_time']))\n",
    "    return md_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata(md_data= None):   \n",
    "    def append_metadata(traj_note,location = '/media/scottzhuang/data/MD/',skip=10,md_data= md_data):\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        if skip == 1:\n",
    "            traj = md.load(location + traj_location,top= location + top_location,stride=10)\n",
    "        else:\n",
    "            traj = md.load(location + traj_location,top= location + top_location)\n",
    "        print(\"In \" + traj_note + \", simulation runs \" + str(10 * traj.n_frames) + \" ns.\")\n",
    "        md_name = traj_note[:traj_note.find('pH')-1]\n",
    "        pH = traj_note[traj_note.find('pH')+2:traj_note.find('pH')+4]\n",
    "        md_replicate = traj_note[-1]\n",
    "        for i in range(0,traj.n_frames):\n",
    "            md_data.loc[md_data.shape[0]+1] = [md_name,pH,md_replicate,i]\n",
    "\n",
    "    for traj_note in traj_notes:\n",
    "        append_metadata(traj_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_system_notation(md_data = None):\n",
    "    system_notation = 0\n",
    "    notation = -1\n",
    "    location = '/media/scottzhuang/data/MD/'\n",
    "    skip=10\n",
    "    notations = []\n",
    "    increment = 0\n",
    "    for traj_note in traj_notes:\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        traj = md.load(location + traj_location,top= location + top_location)\n",
    "        if traj_note.find('md1') >= 0:\n",
    "            notation = notation + 1\n",
    "        if traj_note == '5NJY_I233T_pH70_md4' or traj_note == '4NPQ_pH70_md5' or  traj_note == '4NPQ_F238L_pH70_md3' or traj_note == '4NPQ_I233T_pH70_md3' or traj_note == '4NPQ_F238LI233T_pH70_md3':\n",
    "            notation = notation + 1\n",
    "\n",
    "        for frame in range(0,traj.n_frames):\n",
    "            notations.append(notation)\n",
    "        #if increment % 3 == 2:\n",
    "        #    notation = notation + 1\n",
    "        #increment = increment + 1 \n",
    "        \n",
    "    md_data['system'] = notations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster_data(md_data = None):\n",
    "    cluster_index = []\n",
    "    def add_cluster_data(traj_note,location = '/media/scottzhuang/data/MD/',skip=10):\n",
    "        cluster_data = pd.read_pickle(location + traj_note + '/ward_cluster_labels.pickle')\n",
    "        cluster_index.extend(cluster_data)\n",
    "    for traj_note in traj_notes:\n",
    "        add_cluster_data(traj_note)\n",
    "    md_data['cluster_index'] = cluster_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rmsd_data(md_data= None):\n",
    "    def append_rmsd_data(traj_note,location = '/media/scottzhuang/data/MD/',ref_name = None, skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        traj = md.load(location + traj_location,top= location + top_location)\n",
    "        if ref_name != None:\n",
    "            ref_location = (\"/home/scottzhuang/masterthesis/miscellanies/pdb_ensemble/\" + ref_name + \".pdb\")\n",
    "        else:\n",
    "            ref_location = location + top_location\n",
    "        ref_traj = md.load(ref_location)\n",
    "        topology = traj.topology\n",
    "        if traj.n_atoms != ref_traj.n_atoms:\n",
    "            traj = traj.atom_slice(topology.select(residue_selection))\n",
    "        traj.superpose(ref_traj,0)\n",
    "        rmsd_data.extend(list(md.rmsd(traj, ref_traj)*10))\n",
    "    rmsd_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_rmsd_data(traj_note)\n",
    "    md_data['rmsd']= rmsd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cppca_data(md_data = None,residue_selection_1 = \"resSeq 13 to 198\", residue_selection_2 = \"resSeq 198 to 316\"):\n",
    "    def combined_ppca_reduced_cartesian(residue_selection_1 = \"resSeq 13 to 198\", residue_selection_2 = \"resSeq 198 to 316\"):\n",
    "        wholetraj = md.load(\"/home/scottzhuang/masterthesis/miscellanies/pdb_ensemble/new_ensemble.pdb\")\n",
    "        wholetraj.superpose(wholetraj,28)\n",
    "        topology = wholetraj.topology\n",
    "        wholetraj_sliced_ecd = wholetraj.atom_slice(topology.select(residue_selection_1))\n",
    "        wholetraj_sliced_ecd.superpose(wholetraj_sliced_ecd,28)\n",
    "        wholetraj_sliced_tmd = wholetraj.atom_slice(topology.select(residue_selection_2))\n",
    "        wholetraj_sliced_tmd.superpose(wholetraj_sliced_tmd,28)\n",
    "        ppca_ecd = PCA(n_components=1)\n",
    "        ppca_tmd = PCA(n_components=1)\n",
    "        partial_reduced_cartesian = [ppca_ecd.fit_transform(wholetraj_sliced_ecd.xyz.reshape(wholetraj_sliced_ecd.n_frames, wholetraj_sliced_ecd.n_atoms * 3)), ppca_tmd.fit_transform(wholetraj_sliced_tmd.xyz.reshape(wholetraj_sliced_tmd.n_frames, wholetraj_sliced_tmd.n_atoms * 3))]    \n",
    "        return partial_reduced_cartesian, wholetraj_sliced_ecd, wholetraj_sliced_tmd,ppca_ecd,ppca_tmd\n",
    "    \n",
    "    def append_projection_on_combined_ppca_data(traj_note, location = '/media/scottzhuang/data/MD/',skip = 10, residue_selection_1 = \"resSeq 13 to 198\", residue_selection_2 = \"resSeq 198 to 316\"):\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        traj = md.load(location + traj_location,top= location + top_location)\n",
    "        topology = traj.topology\n",
    "        traj_sliced_ecd = traj.atom_slice(topology.select(residue_selection_1))\n",
    "        traj_sliced_tmd = traj.atom_slice(topology.select(residue_selection_2))\n",
    "\n",
    "        traj_sliced_ecd.superpose(wholetraj_sliced_ecd,28)\n",
    "        traj_sliced_tmd.superpose(wholetraj_sliced_tmd,28)\n",
    "\n",
    "        reduced_cartesian_ecd.extend(ppca_ecd.transform(traj_sliced_ecd.xyz.reshape(traj_sliced_ecd.n_frames, traj_sliced_ecd.n_atoms * 3)).T[0])\n",
    "        reduced_cartesian_tmd.extend(ppca_tmd.transform(traj_sliced_tmd.xyz.reshape(traj_sliced_tmd.n_frames, traj_sliced_tmd.n_atoms * 3)).T[0])\n",
    "    partial_reduced_cartesian, wholetraj_sliced_ecd,wholetraj_sliced_tmd, ppca_ecd,ppca_tmd = combined_ppca_reduced_cartesian(residue_selection_1,residue_selection_2)\n",
    "    reduced_cartesian_ecd = []\n",
    "    reduced_cartesian_tmd = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_projection_on_combined_ppca_data(traj_note)\n",
    "    md_data['ecd_pc1']= reduced_cartesian_ecd\n",
    "    md_data['tmd_pc1']= reduced_cartesian_tmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pca_data(md_data = None):\n",
    "    def ensemble_pca_cartesian():\n",
    "        wholetraj = md.load(\"/home/scottzhuang/masterthesis/miscellanies/pdb_ensemble/new_ensemble.pdb\")\n",
    "        wholetraj.superpose(wholetraj,28)\n",
    "        pca = PCA(n_components=2)\n",
    "        reduced_cartesian = pca.fit_transform(wholetraj.xyz.reshape(wholetraj.n_frames,wholetraj.n_atoms *3))\n",
    "        return wholetraj, pca\n",
    "    def append_pca_data(traj_note,location = '/media/scottzhuang/data/MD/',skip = 10):\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        traj = md.load(location + traj_location,top =location + top_location)\n",
    "        topology = traj.topology\n",
    "        traj = traj.atom_slice(topology.select(\"resSeq 8 to 316\"))\n",
    "        traj.superpose(wholetraj,28)\n",
    "        traj_reduced_cartesian = pca.transform(traj.xyz.reshape(traj.n_frames,traj.n_atoms * 3))\n",
    "        pca1.extend(traj_reduced_cartesian.T[0])\n",
    "        pca2.extend(traj_reduced_cartesian.T[1])\n",
    "    pca1 = []\n",
    "    pca2 = []\n",
    "    wholetraj, pca = ensemble_pca_cartesian()\n",
    "    for traj_note in traj_notes:\n",
    "        append_pca_data(traj_note)\n",
    "    md_data['wholepca_pc1'] = pca1\n",
    "    md_data['wholepca_pc2'] = pca2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gating-related geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_domain_twist_data(md_data = None):\n",
    "    def append_domain_twist(traj_note,location = '/media/scottzhuang/data/MD/',skip = 10):\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        traj = md.load(location + traj_location,top= location + top_location)        \n",
    "        traj.superpose(traj,0)\n",
    "        topology = traj.topology\n",
    "        domain_twist = []\n",
    "        for chain in range (0,5):\n",
    "            residue_selection_1 = \"resid \" + str(8+chain*311) + \" to \" + str(192+chain*311)\n",
    "            residue_selection_2 = \"resid \" + str(192+chain*311) + \" to \" + str(310+chain*311)\n",
    "            traj_sliced_ecd = traj.atom_slice(topology.select(residue_selection_1))\n",
    "            traj_sliced_tmd = traj.atom_slice(topology.select(residue_selection_2))\n",
    "            angle = []\n",
    "            for i in range(0,traj.n_frames):\n",
    "                cen_mass_ecd = md.compute_center_of_mass(traj_sliced_ecd[i])[0]\n",
    "                cen_mass_tmd = md.compute_center_of_mass(traj_sliced_tmd[i])[0]\n",
    "                cen_mass = md.compute_center_of_mass(traj[i])[0]\n",
    "                cen_mass_ecd[2] = cen_mass[2]\n",
    "                cen_mass_tmd[2] = cen_mass[2]\n",
    "                vec_ecd = cen_mass_ecd - cen_mass\n",
    "                vec_tmd = cen_mass_tmd - cen_mass\n",
    "                veclength_ecd = np.sqrt(np.sum(np.power(vec_ecd,2)))\n",
    "                veclength_tmd = np.sqrt(np.sum(np.power(vec_tmd,2)))\n",
    "                angle.append(57.2958 * np.arccos(np.dot(vec_ecd,vec_tmd) /(veclength_ecd * veclength_tmd)))\n",
    "            domain_twist.append(angle)\n",
    "        domain_twist_data.extend(np.mean(np.asarray(domain_twist),axis=0))\n",
    "    domain_twist_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        domain_twist_avg = append_domain_twist(traj_note)\n",
    "    md_data['domain twist']= domain_twist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_helix_tilt_data(md_data = None):\n",
    "    def append_helix_tilt_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        tilt_data = pd.read_csv(location + traj_note + '/' + traj_note + '.tilt.csv',sep=\" \")\n",
    "        tilt_data.columns = ['traj_time','avg','ang1','ang2','ang3','ang4','ang5']\n",
    "        helix_tilt_data.extend(tilt_data['avg'])\n",
    "    helix_tilt_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_helix_tilt_data(traj_note)\n",
    "    md_data['helix tilt angle'] = helix_tilt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_helix_twist_data(md_data = None):\n",
    "    def append_helix_twist_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        twist = pd.read_csv(location + traj_note + '/' + traj_note + '.twist.csv',sep=\" \")\n",
    "        twist.columns = ['traj_time','avg','ang1','ang2','ang3','ang4','ang5']\n",
    "        helix_twist_data.extend(twist['avg'])\n",
    "    helix_twist_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_helix_twist_data(traj_note)\n",
    "    md_data['helix twist angle'] = helix_twist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_beta_expansion(md_data = None):\n",
    "    def append_beta_expansion_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        traj = md.load(location + traj_location,top = location + top_location)\n",
    "        distance = []\n",
    "        for chain in range(0,5):\n",
    "            distance.append(md.compute_distances(traj,[[27 + chain * 311,187 + chain * 311]]))\n",
    "        beta_expansion_data.extend(np.mean(distance,axis=0).T[0])\n",
    "    beta_expansion_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_beta_expansion_data(traj_note)\n",
    "    md_data['beta_expansion'] = beta_expansion_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_M2_radius(md_data = None):\n",
    "    def append_M2_radius_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        traj = md.load(location + traj_location,top = location + top_location)\n",
    "        topology = traj.topology\n",
    "        M2_selection = 'resSeq 231 to 245'\n",
    "        traj_M2 = traj.atom_slice(topology.select(M2_selection))\n",
    "        M2_radius_data.extend(md.compute_rg(traj_M2).T) \n",
    "    M2_radius_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_M2_radius_data(traj_note)\n",
    "    md_data['M2_radius'] = M2_radius_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ECD_radius(md_data = None):\n",
    "    def append_ECD_radius_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        traj = md.load(location + traj_location,top = location + top_location)\n",
    "        topology = traj.topology\n",
    "        ECD_selection = 'resSeq 5 to 194'\n",
    "        traj_ECD = traj.atom_slice(topology.select(ECD_selection))\n",
    "        ECD_radius_data.extend(md.compute_rg(traj_ECD).T) \n",
    "    ECD_radius_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_ECD_radius_data(traj_note)\n",
    "    md_data['ECD_radius'] = ECD_radius_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_M2_M1_distance(md_data = None):\n",
    "    def distance_calculate(x,y):\n",
    "        dist = np.sqrt(np.power(x[0]-y[0],2) + np.power(x[1]-y[1],2) + np.power(x[2]-y[2],2))\n",
    "        return dist\n",
    "    def append_M2_M1_distance_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        traj = md.load(location + traj_location,top = location + top_location)\n",
    "        topology = traj.topology\n",
    "        distance = []\n",
    "        for chain in range(0,4):\n",
    "            M1_selection = 'resid ' + str(192 + chain * 311) + ' to ' + str(196 + chain * 311)\n",
    "            M2_selection = 'resid ' + str(233 + (chain + 1) * 311) + ' to ' + str(238 + (chain + 1) * 311)\n",
    "            traj_M1 = traj.atom_slice(topology.select(M1_selection))\n",
    "            traj_M2 = traj.atom_slice(topology.select(M2_selection))\n",
    "            distance.append(distance_calculate(md.compute_center_of_mass(traj_M1).T,md.compute_center_of_mass(traj_M2).T))\n",
    "        M1_selection = 'resid ' + str(192 + 4 * 311) + ' to ' + str(196 + 4 * 311)\n",
    "        M2_selection = 'resid ' + str(233) + ' to ' + str(238)\n",
    "        traj_M1 = traj.atom_slice(topology.select(M1_selection))\n",
    "        traj_M2 = traj.atom_slice(topology.select(M2_selection))\n",
    "        distance.append(distance_calculate(md.compute_center_of_mass(traj_M1).T,md.compute_center_of_mass(traj_M2).T))\n",
    "        #print((np.mean(np.asarray(distance),axis=0))\n",
    "        M2_M1_distance.extend(np.mean(distance,axis=0))\n",
    "    M2_M1_distance = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_M2_M1_distance_data(traj_note)\n",
    "    md_data['M2_M1_distance'] = M2_M1_distance\n",
    "    #print(M2_M1_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_M1_kink(md_data = None):\n",
    "    def angle_calculate(x,y,z):\n",
    "        angle_set = []\n",
    "        for i in range(0,x.shape[0]):\n",
    "            angle_set.append(180 - 57.29 * np.arccos(np.dot((x[i]-y[i]),(z[i]-y[i]))/(np.linalg.norm(x[i]-y[i]) * np.linalg.norm(z[i]-y[i]))))\n",
    "        return angle_set\n",
    "    def append_M1_kink_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        traj = md.load(location + traj_location,top = location + top_location)\n",
    "        topology = traj.topology\n",
    "        angle = []\n",
    "        for chain in range(0,5):\n",
    "            M1_selection_up = 'resid ' + str(192 + chain * 311) + ' to ' + str(196 + chain * 311)\n",
    "            M1_selection_mid = 'resid ' + str(194 + chain * 311) + ' to ' + str(198 + chain * 311)\n",
    "            M1_selection_down = 'resid ' + str(197 + chain * 311) + ' to ' + str(208 + chain * 311)\n",
    "\n",
    "            M1_up = traj.atom_slice(topology.select(M1_selection_up))\n",
    "            M1_mid = traj.atom_slice(topology.select(M1_selection_mid))\n",
    "            M1_down = traj.atom_slice(topology.select(M1_selection_down))\n",
    "            angle.append(angle_calculate(md.compute_center_of_mass(M1_up), md.compute_center_of_mass(M1_mid), md.compute_center_of_mass(M1_down)))\n",
    "        M1_kink.extend(np.mean(angle,axis=0))\n",
    "    M1_kink = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_M1_kink_data(traj_note)\n",
    "    md_data['M1_kink'] = M1_kink\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pore_profile(md_data = None):\n",
    "    def pore_rad(traj_note,location = '/media/scottzhuang/data/MD/'):\n",
    "        top_location = traj_note + '/' + traj_note + \".protein.gro\"\n",
    "        traj_name = traj_note + '/' + traj_note +  \".skip10.protein.xtc\"    \n",
    "        traj = md.load(location + traj_name,top = location +top_location)\n",
    "        ca_top_location = traj_note + '/' + traj_note +  \".ca.pdb\"\n",
    "        ca_traj_name = traj_note + '/' + traj_note +  \".skip10.ca.xtc\"    \n",
    "        ca_traj = md.load(location + ca_traj_name,top = location + ca_top_location)\n",
    "        topology = traj.topology\n",
    "        pore_profile = pd.DataFrame(columns=['traj_time','resid','pore_radius'])\n",
    "        m = 0\n",
    "        incre = 0\n",
    "        for i in [217,221,225,228,232,235]:\n",
    "            group_1 = np.arange(i,i + 1245, 311)\n",
    "            xyz_inter = np.mean(ca_traj.xyz[:,group_1],axis=1)\n",
    "            chain = topology.add_chain()\n",
    "            residue = topology.add_residue('ALA',chain)\n",
    "            topology.add_atom('H','H',residue)\n",
    "            traj.topology = topology\n",
    "            traj.xyz = np.append(traj.xyz,xyz_inter.reshape([traj.n_frames,1,3]),axis=1)\n",
    "            pairs = list(itertools.product(group_1,[1555 + incre]))\n",
    "            for j in range(0,traj.n_frames):\n",
    "                pore_profile.loc[m] = [j,i,np.mean(md.compute_contacts(traj[j], pairs)[0])]\n",
    "                m = m + 1\n",
    "            incre = incre +1\n",
    "        pore_data_222.extend(pore_profile[pore_profile['resid'] == 217]['pore_radius'])\n",
    "        pore_data_226.extend(pore_profile[pore_profile['resid'] == 221]['pore_radius'])\n",
    "        pore_data_230.extend(pore_profile[pore_profile['resid'] == 225]['pore_radius'])\n",
    "        pore_data_233.extend(pore_profile[pore_profile['resid'] == 228]['pore_radius'])\n",
    "        pore_data_237.extend(pore_profile[pore_profile['resid'] == 232]['pore_radius'])\n",
    "        pore_data_240.extend(pore_profile[pore_profile['resid'] == 235]['pore_radius'])\n",
    "    import itertools\n",
    "    pore_data_222 = []\n",
    "    pore_data_226 = []\n",
    "    pore_data_230 = []\n",
    "    pore_data_233 = []\n",
    "    pore_data_237 = []\n",
    "    pore_data_240 = []\n",
    "\n",
    "    for traj_note in traj_notes:\n",
    "        pore_rad(traj_note)\n",
    "    md_data['pore_profile_222'] = pore_data_222\n",
    "    md_data['pore_profile_226'] = pore_data_226\n",
    "    md_data['pore_profile_230'] = pore_data_230\n",
    "    md_data['pore_profile_233'] = pore_data_233\n",
    "    md_data['pore_profile_237'] = pore_data_237\n",
    "    md_data['pore_profile_240'] = pore_data_240"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Water related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hydration_profile(md_data = None):\n",
    "    def append_hydration_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".system.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".system.xtc\"\n",
    "        traj = mda.Universe(location + top_location,location + traj_location)\n",
    "        hydration = traj.select_atoms(\"(cyzone 7 10 -10 resid 235) and name OW\",updating = True)\n",
    "        for i in range(0,traj.trajectory.n_frames):\n",
    "            traj.trajectory[i]\n",
    "            hydration_data.append(hydration.n_atoms)\n",
    "    hydration_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_hydration_data(traj_note)\n",
    "    md_data['hydration_data'] = hydration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hydration_profile_resid(md_data = None):\n",
    "    def append_hydration_data(traj_note,resid,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".system.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".system.xtc\"\n",
    "        traj = mda.Universe(location + top_location,location + traj_location)\n",
    "        hydration = traj.select_atoms(\"(cyzone 7 3 -3 resid \" + resid + \" ) and name OW\",updating = True)\n",
    "        for i in range(0,traj.trajectory.n_frames):\n",
    "            traj.trajectory[i]\n",
    "            hydration_data.append(hydration.n_atoms)\n",
    "    hydration_data = []\n",
    "    for resid in [235,233,238,226,240]:\n",
    "        for traj_note in traj_notes:\n",
    "            append_hydration_data(traj_note,resid)\n",
    "        md_data['hydration_data' + resid + '_3a'] = hydration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hydration_profile_non_pore(md_data = None):\n",
    "    def append_hydration_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".system.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".system.xtc\"\n",
    "        traj = mda.Universe(location + top_location,location + traj_location)\n",
    "        hydration = traj.select_atoms(\"(cylayer 7 20 8 -8 resid 235) and name OW\",updating = True)\n",
    "        for i in range(0,traj.trajectory.n_frames):\n",
    "            traj.trajectory[i]\n",
    "            hydration_data.append(hydration.n_atoms)\n",
    "    hydration_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_hydration_data(traj_note)\n",
    "    md_data['hydration_data_m123'] = hydration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hydration_profile_non_pore_intra(md_data = None):\n",
    "    def append_hydration_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".system.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".system.xtc\"\n",
    "        traj = mda.Universe(location + top_location,location + traj_location)\n",
    "        hydration = traj.select_atoms(\"(cylayer 7 20 8 -8 resid 235) and name OW and (around 15 resid 304)\",updating = True)\n",
    "        for i in range(0,traj.trajectory.n_frames):\n",
    "            traj.trajectory[i]\n",
    "            hydration_data.append(hydration.n_atoms)\n",
    "    hydration_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_hydration_data(traj_note)\n",
    "    md_data['hydration_data_intra'] = hydration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hydration_profile_non_pore_inter(md_data = None):\n",
    "    def append_hydration_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".system.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".system.xtc\"\n",
    "        traj = mda.Universe(location + top_location,location + traj_location)\n",
    "        hydration = traj.select_atoms(\"(cylayer 7 20 8 -8 resid 235) and name OW and not(around 15 resid 304)\",updating = True)\n",
    "        for i in range(0,traj.trajectory.n_frames):\n",
    "            traj.trajectory[i]\n",
    "            hydration_data.append(hydration.n_atoms)\n",
    "    hydration_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_hydration_data(traj_note)\n",
    "    md_data['hydration_data_inter'] = hydration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_data = pd.read_csv(\"glic_gating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_data.to_csv(\"glic_gating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 5NJY_pH70_md1, simulation runs 1030 ns.\n",
      "In 5NJY_pH70_md2, simulation runs 750 ns.\n",
      "In 5NJY_pH70_md3, simulation runs 810 ns.\n",
      "In 5NJY_F238L_pH70_md1, simulation runs 540 ns.\n",
      "In 5NJY_F238L_pH70_md2, simulation runs 680 ns.\n",
      "In 5NJY_F238L_pH70_md3, simulation runs 720 ns.\n",
      "In 5NJY_I233T_pH70_md4, simulation runs 730 ns.\n",
      "In 5NJY_I233T_pH70_md2, simulation runs 590 ns.\n",
      "In 5NJY_I233T_pH70_md3, simulation runs 820 ns.\n",
      "In 5NJY_F238LI233T_pH70_md1, simulation runs 830 ns.\n",
      "In 5NJY_F238LI233T_pH70_md2, simulation runs 800 ns.\n",
      "In 5NJY_F238LI233T_pH70_md3, simulation runs 880 ns.\n",
      "In 5NJY_pH46_md1, simulation runs 780 ns.\n",
      "In 5NJY_pH46_md2, simulation runs 1060 ns.\n",
      "In 5NJY_pH46_md3, simulation runs 1030 ns.\n",
      "In 5NJY_F238L_pH46_md1, simulation runs 930 ns.\n",
      "In 5NJY_F238L_pH46_md2, simulation runs 950 ns.\n",
      "In 5NJY_F238L_pH46_md3, simulation runs 1090 ns.\n",
      "In 5NJY_I233T_pH46_md1, simulation runs 810 ns.\n",
      "In 5NJY_I233T_pH46_md2, simulation runs 870 ns.\n",
      "In 5NJY_I233T_pH46_md3, simulation runs 980 ns.\n",
      "In 5NJY_F238LI233T_pH46_md1, simulation runs 790 ns.\n",
      "In 5NJY_F238LI233T_pH46_md2, simulation runs 950 ns.\n",
      "In 5NJY_F238LI233T_pH46_md3, simulation runs 960 ns.\n",
      "In 4HFI_pH46_md1, simulation runs 1100 ns.\n",
      "In 4HFI_pH46_md2, simulation runs 1100 ns.\n",
      "In 4HFI_pH46_md3, simulation runs 1070 ns.\n",
      "In 4HFI_F238L_pH46_md1, simulation runs 1040 ns.\n",
      "In 4HFI_F238L_pH46_md2, simulation runs 1010 ns.\n",
      "In 4HFI_F238L_pH46_md3, simulation runs 1040 ns.\n",
      "In 4HFI_I233T_pH46_md1, simulation runs 1030 ns.\n",
      "In 4HFI_I233T_pH46_md2, simulation runs 1030 ns.\n",
      "In 4HFI_I233T_pH46_md3, simulation runs 1030 ns.\n",
      "In 4HFI_F238LI233T_pH46_md1, simulation runs 1060 ns.\n",
      "In 4HFI_F238LI233T_pH46_md2, simulation runs 1010 ns.\n",
      "In 4HFI_F238LI233T_pH46_md3, simulation runs 1120 ns.\n",
      "In 4NPQ_pH70_md5, simulation runs 840 ns.\n",
      "In 4NPQ_pH70_md6, simulation runs 940 ns.\n",
      "In 4NPQ_pH70_md7, simulation runs 1050 ns.\n",
      "In 4NPQ_F238L_pH70_md3, simulation runs 830 ns.\n",
      "In 4NPQ_F238L_pH70_md4, simulation runs 990 ns.\n",
      "In 4NPQ_F238L_pH70_md5, simulation runs 960 ns.\n",
      "In 4NPQ_I233T_pH70_md3, simulation runs 890 ns.\n",
      "In 4NPQ_I233T_pH70_md4, simulation runs 980 ns.\n",
      "In 4NPQ_I233T_pH70_md5, simulation runs 1050 ns.\n",
      "In 4NPQ_F238LI233T_pH70_md3, simulation runs 880 ns.\n",
      "In 4NPQ_F238LI233T_pH70_md4, simulation runs 920 ns.\n",
      "In 4NPQ_F238LI233T_pH70_md5, simulation runs 1010 ns.\n"
     ]
    }
   ],
   "source": [
    "md_data = create_md_dataframe()\n",
    "create_metadata(md_data= md_data)\n",
    "create_system_notation(md_data = md_data)\n",
    "create_rmsd_data(md_data= md_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pca_data(md_data = md_data)\n",
    "create_cppca_data(md_data= md_data)\n",
    "create_domain_twist_data(md_data= md_data)\n",
    "#create_hole_data(md_data= md_data)\n",
    "create_cppca_data_2(md_data)\n",
    "#create_hbond_data(md_data=md_data)\n",
    "create_hydration_profile(md_data)\n",
    "create_hydration_profile_2(md_data)\n",
    "create_hydration_profile_3(md_data)\n",
    "create_hydration_profile_4(md_data)\n",
    "create_hydration_profile_5(md_data)\n",
    "create_hydration_profile_7(md_data)\n",
    "create_pore_profile(md_data)\n",
    "create_helix_tilt_data(md_data)\n",
    "create_helix_twist_data(md_data)\n",
    "create_beta_expansion(md_data)\n",
    "create_M2_radius(md_data)\n",
    "create_ECD_radius(md_data)\n",
    "create_M2_M1_distance(md_data)\n",
    "create_M1_kink(md_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_data.to_csv(\"glic_gating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'MD_name', 'pH', 'replicate', 'traj_time', 'system',\n",
       "       'rmsd', 'wholepca_pc1', 'wholepca_pc2', 'ecd_pc1', 'tmd_pc1',\n",
       "       'domain twist', 'ecd_pc2', 'tmd_pc2', 'hydration_data',\n",
       "       'hydration_data_235_3a', 'hydration_data_233_3a',\n",
       "       'hydration_data_238_3a', 'hydration_data_226_3a',\n",
       "       'hydration_data_240_3a', 'pore_profile_222', 'pore_profile_226',\n",
       "       'pore_profile_230', 'pore_profile_233', 'pore_profile_237',\n",
       "       'pore_profile_240', 'helix tilt angle', 'helix twist angle',\n",
       "       'beta_expansion', 'M2_radius', 'ECD_radius', 'M2_M1_distance',\n",
       "       'M1_kink', 'Hbond_235_259', 'Hbond_200_239', 'Hbond_200_243',\n",
       "       'hydration_data_m123', 'hbond_water_200_239', 'hbond_water_200_243',\n",
       "       'water_bridge_200_243', 'water_bridge_200_239', 'hbond(235, 259)',\n",
       "       'hbond(239, 200)', 'hbond(243, 200)', 'hbond_200_239', 'hbond_200_243',\n",
       "       'hydration_data_intra', 'hydration_data_inter', 'hbond_235_239',\n",
       "       'hbond_235_239_acceptor', 'hbond_235_239_donor'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_data.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepchem",
   "language": "python",
   "name": "deepchem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
