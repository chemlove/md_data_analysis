{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage: function plotting will plot rmsd, rmsd histogram, rmsf and PCA projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import mdtraj as md\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.cluster.hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "import pandas as pd\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import MDAnalysis as mda\n",
    "#XRD Ensemble\n",
    "#28 4NPQ\n",
    "#18 4HFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "residue_selection = 'resSeq 8 to 316'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = '/media/scottzhuang/data/MD/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_notes = ['5NJY_pH70_md1','5NJY_pH70_md2','5NJY_pH70_md3','5NJY_F238L_pH70_md1',\n",
    "                 '5NJY_F238L_pH70_md2','5NJY_F238L_pH70_md3','5NJY_I233T_pH70_md4',\n",
    "                  '5NJY_I233T_pH70_md2','5NJY_I233T_pH70_md3','5NJY_F238LI233T_pH70_md1',\n",
    "                  '5NJY_F238LI233T_pH70_md2','5NJY_F238LI233T_pH70_md3','5NJY_pH46_md1','5NJY_pH46_md2','5NJY_pH46_md3','5NJY_F238L_pH46_md1',\n",
    "                 '5NJY_F238L_pH46_md2','5NJY_F238L_pH46_md3','5NJY_I233T_pH46_md1',\n",
    "                  '5NJY_I233T_pH46_md2','5NJY_I233T_pH46_md3','5NJY_F238LI233T_pH46_md1',\n",
    "                  '5NJY_F238LI233T_pH46_md2','5NJY_F238LI233T_pH46_md3','4HFI_pH46_md1','4HFI_pH46_md2','4HFI_pH46_md3','4HFI_F238L_pH46_md1',\n",
    "                 '4HFI_F238L_pH46_md2','4HFI_F238L_pH46_md3','4HFI_I233T_pH46_md1',\n",
    "                  '4HFI_I233T_pH46_md2','4HFI_I233T_pH46_md3','4HFI_F238LI233T_pH46_md1',\n",
    "                  '4HFI_F238LI233T_pH46_md2','4HFI_F238LI233T_pH46_md3','4NPQ_pH70_md5','4NPQ_pH70_md6','4NPQ_pH70_md7','4NPQ_F238L_pH70_md3',\n",
    "                 '4NPQ_F238L_pH70_md4','4NPQ_F238L_pH70_md5','4NPQ_I233T_pH70_md3',\n",
    "                  '4NPQ_I233T_pH70_md4','4NPQ_I233T_pH70_md5','4NPQ_F238LI233T_pH70_md3',\n",
    "                  '4NPQ_F238LI233T_pH70_md4','4NPQ_F238LI233T_pH70_md5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_md_dataframe():    \n",
    "    md_data = pd.DataFrame(columns=list(['MD_name','pH','replicate','traj_time']))\n",
    "    return md_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata(md_data= None):   \n",
    "    def append_metadata(traj_note,location = '/media/scottzhuang/data/MD/',skip=10,md_data= md_data):\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        if skip == 1:\n",
    "            traj = md.load(location + traj_location,top= location + top_location,stride=10)\n",
    "        else:\n",
    "            traj = md.load(location + traj_location,top= location + top_location)\n",
    "        print(\"In \" + traj_note + \", simulation runs \" + str(10 * traj.n_frames) + \" ns.\")\n",
    "        md_name = traj_note[:traj_note.find('pH')-1]\n",
    "        pH = traj_note[traj_note.find('pH')+2:traj_note.find('pH')+4]\n",
    "        md_replicate = traj_note[-1]\n",
    "        for i in range(0,traj.n_frames):\n",
    "            md_data.loc[md_data.shape[0]+1] = [md_name,pH,md_replicate,i]\n",
    "\n",
    "    for traj_note in traj_notes:\n",
    "        append_metadata(traj_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_system_notation(md_data = None):\n",
    "    system_notation = 0\n",
    "    notation = -1\n",
    "    location = '/media/scottzhuang/data/MD/'\n",
    "    skip=10\n",
    "    notations = []\n",
    "    increment = 0\n",
    "    for traj_note in traj_notes:\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        traj = md.load(location + traj_location,top= location + top_location)\n",
    "        if traj_note.find('md1') >= 0:\n",
    "            notation = notation + 1\n",
    "        if traj_note == '5NJY_I233T_pH70_md4' or traj_note == '4NPQ_pH70_md5' or  traj_note == '4NPQ_F238L_pH70_md3' or traj_note == '4NPQ_I233T_pH70_md3' or traj_note == '4NPQ_F238LI233T_pH70_md3':\n",
    "            notation = notation + 1\n",
    "\n",
    "        for frame in range(0,traj.n_frames):\n",
    "            notations.append(notation)\n",
    "        #if increment % 3 == 2:\n",
    "        #    notation = notation + 1\n",
    "        #increment = increment + 1 \n",
    "        \n",
    "    md_data['system'] = notations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rmsd_data(md_data= None):\n",
    "    def append_rmsd_data(traj_note,location = '/media/scottzhuang/data/MD/',ref_name = None, skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        traj = md.load(location + traj_location,top= location + top_location)\n",
    "        if ref_name != None:\n",
    "            ref_location = (\"/home/scottzhuang/masterthesis/miscellanies/pdb_ensemble/\" + ref_name + \".pdb\")\n",
    "        else:\n",
    "            ref_location = location + top_location\n",
    "        ref_traj = md.load(ref_location)\n",
    "        topology = traj.topology\n",
    "        if traj.n_atoms != ref_traj.n_atoms:\n",
    "            traj = traj.atom_slice(topology.select(residue_selection))\n",
    "        traj.superpose(ref_traj,0)\n",
    "        rmsd_data.extend(list(md.rmsd(traj, ref_traj)*10))\n",
    "    rmsd_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_rmsd_data(traj_note)\n",
    "    md_data['rmsd']= rmsd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cppca_data(md_data = None,residue_selection_1 = \"resSeq 13 to 198\", residue_selection_2 = \"resSeq 198 to 316\"):\n",
    "    def combined_ppca_reduced_cartesian(residue_selection_1 = \"resSeq 13 to 198\", residue_selection_2 = \"resSeq 198 to 316\"):\n",
    "        wholetraj = md.load(\"/home/scottzhuang/masterthesis/miscellanies/pdb_ensemble/new_ensemble.pdb\")\n",
    "        wholetraj.superpose(wholetraj,28)\n",
    "        topology = wholetraj.topology\n",
    "        wholetraj_sliced_ecd = wholetraj.atom_slice(topology.select(residue_selection_1))\n",
    "        wholetraj_sliced_ecd.superpose(wholetraj_sliced_ecd,28)\n",
    "        wholetraj_sliced_tmd = wholetraj.atom_slice(topology.select(residue_selection_2))\n",
    "        wholetraj_sliced_tmd.superpose(wholetraj_sliced_tmd,28)\n",
    "        ppca_ecd = PCA(n_components=1)\n",
    "        ppca_tmd = PCA(n_components=1)\n",
    "        partial_reduced_cartesian = [ppca_ecd.fit_transform(wholetraj_sliced_ecd.xyz.reshape(wholetraj_sliced_ecd.n_frames, wholetraj_sliced_ecd.n_atoms * 3)), ppca_tmd.fit_transform(wholetraj_sliced_tmd.xyz.reshape(wholetraj_sliced_tmd.n_frames, wholetraj_sliced_tmd.n_atoms * 3))]    \n",
    "        return partial_reduced_cartesian, wholetraj_sliced_ecd, wholetraj_sliced_tmd,ppca_ecd,ppca_tmd\n",
    "    \n",
    "    def append_projection_on_combined_ppca_data(traj_note, location = '/media/scottzhuang/data/MD/',skip = 10, residue_selection_1 = \"resSeq 13 to 198\", residue_selection_2 = \"resSeq 198 to 316\"):\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        traj = md.load(location + traj_location,top= location + top_location)\n",
    "        topology = traj.topology\n",
    "        traj_sliced_ecd = traj.atom_slice(topology.select(residue_selection_1))\n",
    "        traj_sliced_tmd = traj.atom_slice(topology.select(residue_selection_2))\n",
    "\n",
    "        traj_sliced_ecd.superpose(wholetraj_sliced_ecd,28)\n",
    "        traj_sliced_tmd.superpose(wholetraj_sliced_tmd,28)\n",
    "\n",
    "        reduced_cartesian_ecd.extend(ppca_ecd.transform(traj_sliced_ecd.xyz.reshape(traj_sliced_ecd.n_frames, traj_sliced_ecd.n_atoms * 3)).T[0])\n",
    "        reduced_cartesian_tmd.extend(ppca_tmd.transform(traj_sliced_tmd.xyz.reshape(traj_sliced_tmd.n_frames, traj_sliced_tmd.n_atoms * 3)).T[0])\n",
    "    partial_reduced_cartesian, wholetraj_sliced_ecd,wholetraj_sliced_tmd, ppca_ecd,ppca_tmd = combined_ppca_reduced_cartesian(residue_selection_1,residue_selection_2)\n",
    "    reduced_cartesian_ecd = []\n",
    "    reduced_cartesian_tmd = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_projection_on_combined_ppca_data(traj_note)\n",
    "    md_data['ecd_pc1']= reduced_cartesian_ecd\n",
    "    md_data['tmd_pc1']= reduced_cartesian_tmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cppca_data_2(md_data = None,residue_selection_1 = \"resSeq 13 to 198\", residue_selection_2 = \"resSeq 198 to 316\"):\n",
    "    def combined_ppca_reduced_cartesian(residue_selection_1 = \"resSeq 13 to 198\", residue_selection_2 = \"resSeq 198 to 316\"):\n",
    "        wholetraj = md.load(\"/home/scottzhuang/masterthesis/miscellanies/pdb_ensemble/new_ensemble.pdb\")\n",
    "        wholetraj.superpose(wholetraj,28)\n",
    "        topology = wholetraj.topology\n",
    "        wholetraj_sliced_ecd = wholetraj.atom_slice(topology.select(residue_selection_1))\n",
    "        wholetraj_sliced_ecd.superpose(wholetraj_sliced_ecd,28)\n",
    "        wholetraj_sliced_tmd = wholetraj.atom_slice(topology.select(residue_selection_2))\n",
    "        wholetraj_sliced_tmd.superpose(wholetraj_sliced_tmd,28)\n",
    "        ppca_ecd = PCA(n_components=2)\n",
    "        ppca_tmd = PCA(n_components=2)\n",
    "        partial_reduced_cartesian = [ppca_ecd.fit_transform(wholetraj_sliced_ecd.xyz.reshape(wholetraj_sliced_ecd.n_frames, wholetraj_sliced_ecd.n_atoms * 3)), ppca_tmd.fit_transform(wholetraj_sliced_tmd.xyz.reshape(wholetraj_sliced_tmd.n_frames, wholetraj_sliced_tmd.n_atoms * 3))]    \n",
    "        return partial_reduced_cartesian, wholetraj_sliced_ecd, wholetraj_sliced_tmd,ppca_ecd,ppca_tmd\n",
    "    \n",
    "    def append_projection_on_combined_ppca_data(traj_note, location = '/media/scottzhuang/data/MD/',skip = 10, residue_selection_1 = \"resSeq 13 to 198\", residue_selection_2 = \"resSeq 198 to 316\"):\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        traj = md.load(location + traj_location,top= location + top_location)\n",
    "        topology = traj.topology\n",
    "        traj_sliced_ecd = traj.atom_slice(topology.select(residue_selection_1))\n",
    "        traj_sliced_tmd = traj.atom_slice(topology.select(residue_selection_2))\n",
    "\n",
    "        traj_sliced_ecd.superpose(wholetraj_sliced_ecd,28)\n",
    "        traj_sliced_tmd.superpose(wholetraj_sliced_tmd,28)\n",
    "\n",
    "        reduced_cartesian_ecd.extend(ppca_ecd.transform(traj_sliced_ecd.xyz.reshape(traj_sliced_ecd.n_frames, traj_sliced_ecd.n_atoms * 3)).T[1])\n",
    "        reduced_cartesian_tmd.extend(ppca_tmd.transform(traj_sliced_tmd.xyz.reshape(traj_sliced_tmd.n_frames, traj_sliced_tmd.n_atoms * 3)).T[1])\n",
    "    partial_reduced_cartesian, wholetraj_sliced_ecd,wholetraj_sliced_tmd, ppca_ecd,ppca_tmd = combined_ppca_reduced_cartesian(residue_selection_1,residue_selection_2)\n",
    "    reduced_cartesian_ecd = []\n",
    "    reduced_cartesian_tmd = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_projection_on_combined_ppca_data(traj_note)\n",
    "    md_data['ecd_pc2']= reduced_cartesian_ecd\n",
    "    md_data['tmd_pc2']= reduced_cartesian_tmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pca_data(md_data = None):\n",
    "    def ensemble_pca_cartesian():\n",
    "        wholetraj = md.load(\"/home/scottzhuang/masterthesis/miscellanies/pdb_ensemble/new_ensemble.pdb\")\n",
    "        wholetraj.superpose(wholetraj,28)\n",
    "        pca = PCA(n_components=2)\n",
    "        reduced_cartesian = pca.fit_transform(wholetraj.xyz.reshape(wholetraj.n_frames,wholetraj.n_atoms *3))\n",
    "        return wholetraj, pca\n",
    "    def append_pca_data(traj_note,location = '/media/scottzhuang/data/MD/',skip = 10):\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        traj = md.load(location + traj_location,top =location + top_location)\n",
    "        topology = traj.topology\n",
    "        traj = traj.atom_slice(topology.select(\"resSeq 8 to 316\"))\n",
    "        traj.superpose(wholetraj,28)\n",
    "        traj_reduced_cartesian = pca.transform(traj.xyz.reshape(traj.n_frames,traj.n_atoms * 3))\n",
    "        pca1.extend(traj_reduced_cartesian.T[0])\n",
    "        pca2.extend(traj_reduced_cartesian.T[1])\n",
    "    pca1 = []\n",
    "    pca2 = []\n",
    "    wholetraj, pca = ensemble_pca_cartesian()\n",
    "    for traj_note in traj_notes:\n",
    "        append_pca_data(traj_note)\n",
    "    md_data['wholepca_pc1'] = pca1\n",
    "    md_data['wholepca_pc2'] = pca2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_domain_twist_data(md_data = None):\n",
    "    def append_domain_twist(traj_note,location = '/media/scottzhuang/data/MD/',skip = 10):\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        traj = md.load(location + traj_location,top= location + top_location)        \n",
    "        traj.superpose(traj,0)\n",
    "        topology = traj.topology\n",
    "        domain_twist = []\n",
    "        for chain in range (0,5):\n",
    "            residue_selection_1 = \"resid \" + str(8+chain*311) + \" to \" + str(192+chain*311)\n",
    "            residue_selection_2 = \"resid \" + str(192+chain*311) + \" to \" + str(310+chain*311)\n",
    "            traj_sliced_ecd = traj.atom_slice(topology.select(residue_selection_1))\n",
    "            traj_sliced_tmd = traj.atom_slice(topology.select(residue_selection_2))\n",
    "            angle = []\n",
    "            for i in range(0,traj.n_frames):\n",
    "                cen_mass_ecd = md.compute_center_of_mass(traj_sliced_ecd[i])[0]\n",
    "                cen_mass_tmd = md.compute_center_of_mass(traj_sliced_tmd[i])[0]\n",
    "                cen_mass = md.compute_center_of_mass(traj[i])[0]\n",
    "                cen_mass_ecd[2] = cen_mass[2]\n",
    "                cen_mass_tmd[2] = cen_mass[2]\n",
    "                vec_ecd = cen_mass_ecd - cen_mass\n",
    "                vec_tmd = cen_mass_tmd - cen_mass\n",
    "                veclength_ecd = np.sqrt(np.sum(np.power(vec_ecd,2)))\n",
    "                veclength_tmd = np.sqrt(np.sum(np.power(vec_tmd,2)))\n",
    "                angle.append(57.2958 * np.arccos(np.dot(vec_ecd,vec_tmd) /(veclength_ecd * veclength_tmd)))\n",
    "            domain_twist.append(angle)\n",
    "        domain_twist_data.extend(np.mean(np.asarray(domain_twist),axis=0))\n",
    "    domain_twist_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        domain_twist_avg = append_domain_twist(traj_note)\n",
    "    md_data['domain twist']= domain_twist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hole_data(md_data = None):\n",
    "    import MDAnalysis as mda\n",
    "    from MDAnalysis.analysis.hole import HOLEtraj\n",
    "    def append_hole_data(traj_note,location = '/media/scottzhuang/data/MD/',skip = 10): \n",
    "        hole_traj_location = location + traj_note + '/' + traj_note + \".hole.traj.pdb\"\n",
    "        u = mda.Universe(hole_traj_location)\n",
    "        H = HOLEtraj(u, executable=\"~/hole2/exe/hole\")\n",
    "        H.run()\n",
    "        hole_data.extend(H.min_radius().T[1])\n",
    "    hole_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_hole_data(traj_note)\n",
    "    md_data['min hole radius']=hole_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_helix_tilt_data(md_data = None):\n",
    "    def append_helix_tilt_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        tilt_data = pd.read_csv(location + traj_note + '/' + traj_note + '.tilt.csv',sep=\" \")\n",
    "        tilt_data.columns = ['traj_time','avg','ang1','ang2','ang3','ang4','ang5']\n",
    "        helix_tilt_data.extend(tilt_data['avg'])\n",
    "    helix_tilt_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_helix_tilt_data(traj_note)\n",
    "    md_data['helix tilt angle'] = helix_tilt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_helix_twist_data(md_data = None):\n",
    "    def append_helix_twist_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        twist = pd.read_csv(location + traj_note + '/' + traj_note + '.twist.csv',sep=\" \")\n",
    "        twist.columns = ['traj_time','avg','ang1','ang2','ang3','ang4','ang5']\n",
    "        helix_twist_data.extend(twist['avg'])\n",
    "    helix_twist_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_helix_twist_data(traj_note)\n",
    "    md_data['helix twist angle'] = helix_twist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pore_profile(md_data = None):\n",
    "    def pore_rad(traj_note,location = '/media/scottzhuang/data/MD/'):\n",
    "        top_location = traj_note + '/' + traj_note + \".protein.gro\"\n",
    "        traj_name = traj_note + '/' + traj_note +  \".skip10.protein.xtc\"    \n",
    "        traj = md.load(location + traj_name,top = location +top_location)\n",
    "        ca_top_location = traj_note + '/' + traj_note +  \".ca.pdb\"\n",
    "        ca_traj_name = traj_note + '/' + traj_note +  \".skip10.ca.xtc\"    \n",
    "        ca_traj = md.load(location + ca_traj_name,top = location + ca_top_location)\n",
    "        topology = traj.topology\n",
    "        pore_profile = pd.DataFrame(columns=['traj_time','resid','pore_radius'])\n",
    "        m = 0\n",
    "        incre = 0\n",
    "        for i in [217,221,225,228,232,235]:\n",
    "            group_1 = np.arange(i,i + 1245, 311)\n",
    "            xyz_inter = np.mean(ca_traj.xyz[:,group_1],axis=1)\n",
    "            chain = topology.add_chain()\n",
    "            residue = topology.add_residue('ALA',chain)\n",
    "            topology.add_atom('H','H',residue)\n",
    "            traj.topology = topology\n",
    "            traj.xyz = np.append(traj.xyz,xyz_inter.reshape([traj.n_frames,1,3]),axis=1)\n",
    "            pairs = list(itertools.product(group_1,[1555 + incre]))\n",
    "            for j in range(0,traj.n_frames):\n",
    "                pore_profile.loc[m] = [j,i,np.mean(md.compute_contacts(traj[j], pairs)[0])]\n",
    "                m = m + 1\n",
    "            incre = incre +1\n",
    "        pore_data_222.extend(pore_profile[pore_profile['resid'] == 217]['pore_radius'])\n",
    "        pore_data_226.extend(pore_profile[pore_profile['resid'] == 221]['pore_radius'])\n",
    "        pore_data_230.extend(pore_profile[pore_profile['resid'] == 225]['pore_radius'])\n",
    "        pore_data_233.extend(pore_profile[pore_profile['resid'] == 228]['pore_radius'])\n",
    "        pore_data_237.extend(pore_profile[pore_profile['resid'] == 232]['pore_radius'])\n",
    "        pore_data_240.extend(pore_profile[pore_profile['resid'] == 235]['pore_radius'])\n",
    "    import itertools\n",
    "    pore_data_222 = []\n",
    "    pore_data_226 = []\n",
    "    pore_data_230 = []\n",
    "    pore_data_233 = []\n",
    "    pore_data_237 = []\n",
    "    pore_data_240 = []\n",
    "\n",
    "    for traj_note in traj_notes:\n",
    "        pore_rad(traj_note)\n",
    "    md_data['pore_profile_222'] = pore_data_222\n",
    "    md_data['pore_profile_226'] = pore_data_226\n",
    "    md_data['pore_profile_230'] = pore_data_230\n",
    "    md_data['pore_profile_233'] = pore_data_233\n",
    "    md_data['pore_profile_237'] = pore_data_237\n",
    "    md_data['pore_profile_240'] = pore_data_240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hydration_profile(md_data = None):\n",
    "    def append_hydration_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".system.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".system.xtc\"\n",
    "        traj = mda.Universe(location + top_location,location + traj_location)\n",
    "        hydration = traj.select_atoms(\"(cyzone 7 10 -10 resid 235) and name OW\",updating = True)\n",
    "        for i in range(0,traj.trajectory.n_frames):\n",
    "            traj.trajectory[i]\n",
    "            hydration_data.append(hydration.n_atoms)\n",
    "    hydration_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_hydration_data(traj_note)\n",
    "    md_data['hydration_data'] = hydration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hydration_profile_2(md_data = None):\n",
    "    def append_hydration_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".system.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".system.xtc\"\n",
    "        traj = mda.Universe(location + top_location,location + traj_location)\n",
    "        hydration = traj.select_atoms(\"(cyzone 7 3 -3 resid 235) and name OW\",updating = True)\n",
    "        for i in range(0,traj.trajectory.n_frames):\n",
    "            traj.trajectory[i]\n",
    "            hydration_data.append(hydration.n_atoms)\n",
    "    hydration_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_hydration_data(traj_note)\n",
    "    md_data['hydration_data_235_3a'] = hydration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hydration_profile_3(md_data = None):\n",
    "    def append_hydration_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".system.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".system.xtc\"\n",
    "        traj = mda.Universe(location + top_location,location + traj_location)\n",
    "        hydration = traj.select_atoms(\"(cyzone 7 3 -3 resid 233) and name OW\",updating = True)\n",
    "        for i in range(0,traj.trajectory.n_frames):\n",
    "            traj.trajectory[i]\n",
    "            hydration_data.append(hydration.n_atoms)\n",
    "    hydration_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_hydration_data(traj_note)\n",
    "    md_data['hydration_data_233_3a'] = hydration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hydration_profile_4(md_data = None):\n",
    "    def append_hydration_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".system.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".system.xtc\"\n",
    "        traj = mda.Universe(location + top_location,location + traj_location)\n",
    "        hydration = traj.select_atoms(\"(cyzone 7 3 -3 resid 238) and name OW\",updating = True)\n",
    "        for i in range(0,traj.trajectory.n_frames):\n",
    "            traj.trajectory[i]\n",
    "            hydration_data.append(hydration.n_atoms)\n",
    "    hydration_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_hydration_data(traj_note)\n",
    "    md_data['hydration_data_238_3a'] = hydration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hydration_profile_5(md_data = None):\n",
    "    def append_hydration_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".system.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".system.xtc\"\n",
    "        traj = mda.Universe(location + top_location,location + traj_location)\n",
    "        hydration = traj.select_atoms(\"(cyzone 7 3 -3 resid 226) and name OW\",updating = True)\n",
    "        for i in range(0,traj.trajectory.n_frames):\n",
    "            traj.trajectory[i]\n",
    "            hydration_data.append(hydration.n_atoms)\n",
    "    hydration_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_hydration_data(traj_note)\n",
    "    md_data['hydration_data_226_3a'] = hydration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hydration_profile_7(md_data = None):\n",
    "    def append_hydration_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".system.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".system.xtc\"\n",
    "        traj = mda.Universe(location + top_location,location + traj_location)\n",
    "        hydration = traj.select_atoms(\"(cyzone 7 3 -3 resid 240) and name OW\",updating = True)\n",
    "        for i in range(0,traj.trajectory.n_frames):\n",
    "            traj.trajectory[i]\n",
    "            hydration_data.append(hydration.n_atoms)\n",
    "    hydration_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_hydration_data(traj_note)\n",
    "    md_data['hydration_data_240_3a'] = hydration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hydration_profile_8(md_data = None):\n",
    "    def append_hydration_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".system.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".system.xtc\"\n",
    "        traj = mda.Universe(location + top_location,location + traj_location)\n",
    "        hydration = traj.select_atoms(\"(cylayer 7 20 8 -8 resid 235) and name OW\",updating = True)\n",
    "        for i in range(0,traj.trajectory.n_frames):\n",
    "            traj.trajectory[i]\n",
    "            hydration_data.append(hydration.n_atoms)\n",
    "    hydration_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_hydration_data(traj_note)\n",
    "    md_data['hydration_data_m123'] = hydration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hydration_profile_9(md_data = None):\n",
    "    def append_hydration_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".system.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".system.xtc\"\n",
    "        traj = mda.Universe(location + top_location,location + traj_location)\n",
    "        hydration = traj.select_atoms(\"(cylayer 7 20 8 -8 resid 235) and name OW and (around 15 resid 304)\",updating = True)\n",
    "        for i in range(0,traj.trajectory.n_frames):\n",
    "            traj.trajectory[i]\n",
    "            hydration_data.append(hydration.n_atoms)\n",
    "    hydration_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_hydration_data(traj_note)\n",
    "    md_data['hydration_data_intra'] = hydration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hydration_profile_10(md_data = None):\n",
    "    def append_hydration_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".system.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".system.xtc\"\n",
    "        traj = mda.Universe(location + top_location,location + traj_location)\n",
    "        hydration = traj.select_atoms(\"(cylayer 7 20 8 -8 resid 235) and name OW and not(around 15 resid 304)\",updating = True)\n",
    "        for i in range(0,traj.trajectory.n_frames):\n",
    "            traj.trajectory[i]\n",
    "            hydration_data.append(hydration.n_atoms)\n",
    "    hydration_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_hydration_data(traj_note)\n",
    "    md_data['hydration_data_inter'] = hydration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_beta_expansion(md_data = None):\n",
    "    def append_beta_expansion_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        traj = md.load(location + traj_location,top = location + top_location)\n",
    "        distance = []\n",
    "        for chain in range(0,5):\n",
    "            distance.append(md.compute_distances(traj,[[27 + chain * 311,187 + chain * 311]]))\n",
    "        beta_expansion_data.extend(np.mean(distance,axis=0).T[0])\n",
    "    beta_expansion_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_beta_expansion_data(traj_note)\n",
    "    md_data['beta_expansion'] = beta_expansion_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_beta_expansion_2(md_data = None):\n",
    "    def distance_calculate(x,y):\n",
    "        dist = np.sqrt(np.power(x[0]-y[0],2) + np.power(x[1]-y[1],2) + np.power(x[2]-y[2],2))\n",
    "        return dist\n",
    "\n",
    "    def append_beta_expansion_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        traj = md.load(location + traj_location,top = location + top_location)\n",
    "        topology = traj.topology\n",
    "\n",
    "        distance = []\n",
    "        for chain in range(0,5):\n",
    "            M1_selection = 'resid ' + str(25 + chain * 311) + ' to ' + str(29 + chain * 311)\n",
    "            M2_selection = 'resid ' + str(185 + chain * 311) + ' to ' + str(189 + chain * 311)\n",
    "            traj_M1 = traj.atom_slice(topology.select(M1_selection))\n",
    "            traj_M2 = traj.atom_slice(topology.select(M2_selection))\n",
    "            distance.append(distance_calculate(md.compute_center_of_mass(traj_M1).T,md.compute_center_of_mass(traj_M2).T))\n",
    "        beta_expansion_data.extend(np.mean(distance,axis=0))\n",
    "    beta_expansion_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_beta_expansion_data(traj_note)\n",
    "    md_data['beta_expansion_2'] = beta_expansion_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_beta_expansion_2(md_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_M2_radius(md_data = None):\n",
    "    def append_M2_radius_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        traj = md.load(location + traj_location,top = location + top_location)\n",
    "        topology = traj.topology\n",
    "        M2_selection = 'resSeq 231 to 245'\n",
    "        traj_M2 = traj.atom_slice(topology.select(M2_selection))\n",
    "        M2_radius_data.extend(md.compute_rg(traj_M2).T) \n",
    "    M2_radius_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_M2_radius_data(traj_note)\n",
    "    md_data['M2_radius'] = M2_radius_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ECD_radius(md_data = None):\n",
    "    def append_ECD_radius_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        traj = md.load(location + traj_location,top = location + top_location)\n",
    "        topology = traj.topology\n",
    "        ECD_selection = 'resSeq 5 to 194'\n",
    "        traj_ECD = traj.atom_slice(topology.select(ECD_selection))\n",
    "        ECD_radius_data.extend(md.compute_rg(traj_ECD).T) \n",
    "    ECD_radius_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_ECD_radius_data(traj_note)\n",
    "    md_data['ECD_radius'] = ECD_radius_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_M2_M1_distance(md_data = None):\n",
    "    def distance_calculate(x,y):\n",
    "        dist = np.sqrt(np.power(x[0]-y[0],2) + np.power(x[1]-y[1],2) + np.power(x[2]-y[2],2))\n",
    "        return dist\n",
    "    def append_M2_M1_distance_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        traj = md.load(location + traj_location,top = location + top_location)\n",
    "        topology = traj.topology\n",
    "        distance = []\n",
    "        for chain in range(0,4):\n",
    "            M1_selection = 'resid ' + str(195 + chain * 311) + ' to ' + str(199 + chain * 311)\n",
    "            M2_selection = 'resid ' + str(236 + (chain + 1) * 311) + ' to ' + str(240 + (chain + 1) * 311)\n",
    "            traj_M1 = traj.atom_slice(topology.select(M1_selection))\n",
    "            traj_M2 = traj.atom_slice(topology.select(M2_selection))\n",
    "            distance.append(distance_calculate(md.compute_center_of_mass(traj_M1).T,md.compute_center_of_mass(traj_M2).T))\n",
    "        M1_selection = 'resid ' + str(195 + 4 * 311) + ' to ' + str(199 + 4 * 311)\n",
    "        M2_selection = 'resid ' + str(236) + ' to ' + str(240)\n",
    "        traj_M1 = traj.atom_slice(topology.select(M1_selection))\n",
    "        traj_M2 = traj.atom_slice(topology.select(M2_selection))\n",
    "        distance.append(distance_calculate(md.compute_center_of_mass(traj_M1).T,md.compute_center_of_mass(traj_M2).T))\n",
    "        #print((np.mean(np.asarray(distance),axis=0))\n",
    "        M2_M1_distance.extend(np.mean(distance,axis=0))\n",
    "    M2_M1_distance = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_M2_M1_distance_data(traj_note)\n",
    "    md_data['M2_M1_distance'] = M2_M1_distance\n",
    "    #print(M2_M1_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_data = pd.read_pickle('glic_gating.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_M2_M1_distance(md_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_M1_kink(md_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_data.to_pickle('glic_gating.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_M1_kink(md_data = None):\n",
    "    def angle_calculate(x,y,z):\n",
    "        angle_set = []\n",
    "        for i in range(0,x.shape[0]):\n",
    "            angle_set.append(180 - 57.29 * np.arccos(np.dot((x[i]-y[i]),(z[i]-y[i]))/(np.linalg.norm(x[i]-y[i]) * np.linalg.norm(z[i]-y[i]))))\n",
    "        return angle_set\n",
    "    def append_M1_kink_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        traj = md.load(location + traj_location,top = location + top_location)\n",
    "        topology = traj.topology\n",
    "        angle = []\n",
    "        for chain in range(0,5):\n",
    "            M1_selection_up = 'resid ' + str(195 + chain * 311) + ' to ' + str(199 + chain * 311)\n",
    "            M1_selection_mid = 'resid ' + str(197 + chain * 311) + ' to ' + str(201 + chain * 311)\n",
    "            M1_selection_down = 'resid ' + str(200 + chain * 311) + ' to ' + str(211 + chain * 311)\n",
    "\n",
    "            M1_up = traj.atom_slice(topology.select(M1_selection_up))\n",
    "            M1_mid = traj.atom_slice(topology.select(M1_selection_mid))\n",
    "            M1_down = traj.atom_slice(topology.select(M1_selection_down))\n",
    "            angle.append(angle_calculate(md.compute_center_of_mass(M1_up), md.compute_center_of_mass(M1_mid), md.compute_center_of_mass(M1_down)))\n",
    "        M1_kink.extend(np.mean(angle,axis=0))\n",
    "    M1_kink = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_M1_kink_data(traj_note)\n",
    "    md_data['M1_kink'] = M1_kink\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hbond_resid_data(md_data = None):\n",
    "    def add_hbond_data(traj_note,hbond_resid_selection,location = '/media/scottzhuang/data/MD/',):\n",
    "        hbond_data = pd.read_csv(location + traj_note + '/hbond.csv')\n",
    "        for time in set(hbond_data['time'].tolist()):\n",
    "            hbond_resid_data.append(len(hbond_data[(hbond_data['donor_resid'] == hbond_resid_selection[0]) & (hbond_data['acceptor_resid'] == hbond_resid_selection[1]) & (hbond_data['time'] == time)]))\n",
    "    for hbond_resid_selection in zip((235,239,243),(259,200,200)):\n",
    "        hbond_resid_data = []\n",
    "        for traj_note in traj_notes:\n",
    "            add_hbond_data(traj_note,hbond_resid_selection)\n",
    "        md_data['hbond' + str(hbond_resid_selection)] = hbond_resid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hbond_239_235_data(md_data = None):\n",
    "    def add_hbond_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        hbond_data = pd.read_csv(location + traj_note + '/resid235_239_hbond.csv')\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        n_frames = md.load(location + traj_location,top = location + top_location).n_frames\n",
    "        for time in range(0,n_frames*10000,10000):\n",
    "            hbond_resid_data.append(len(hbond_data[(hbond_data['time'] == time)]))\n",
    "    hbond_resid_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        add_hbond_data(traj_note)\n",
    "    md_data['hbond_235_239'] = hbond_resid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hbond_239_235_data(md_data = None):\n",
    "    def add_hbond_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        hbond_data = pd.read_csv(location + traj_note + '/resid235_239_hbond.csv')\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        n_frames = md.load(location + traj_location,top = location + top_location).n_frames\n",
    "        for time in range(0,n_frames*10000,10000):\n",
    "            hbond_resid_data.append(len(hbond_data[(hbond_data['time'] == time) & ((hbond_data['donor_atom'] == 'HD21') | (hbond_data['donor_atom'] == 'HD22'))]))\n",
    "    hbond_resid_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        add_hbond_data(traj_note)\n",
    "    md_data['hbond_235_239_donor'] = hbond_resid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hbond_resid_200_239_data(md_data = None):\n",
    "    def add_hbond_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        hbond_data = pd.read_csv(location + traj_note + '/resid200_239_hbond.csv')\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        n_frames = md.load(location + traj_location,top = location + top_location).n_frames\n",
    "        for time in range(0,n_frames*10000,10000):                        \n",
    "            hbond_resid_data.append(len(hbond_data[hbond_data['time'] == time]))\n",
    "    hbond_resid_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        add_hbond_data(traj_note)\n",
    "    md_data['hbond_200_239'] = hbond_resid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hbond_resid_200_243_data(md_data = None):\n",
    "    def add_hbond_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        hbond_data = pd.read_csv(location + traj_note + '/resid200_243_hbond.csv')\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        n_frames = md.load(location + traj_location,top = location + top_location).n_frames\n",
    "        for time in range(0,n_frames*10000,10000):                        \n",
    "            hbond_resid_data.append(len(hbond_data[hbond_data['time'] == time]))\n",
    "    hbond_resid_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        add_hbond_data(traj_note)\n",
    "    md_data['hbond_200_243'] = hbond_resid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Hbond_235_259(md_data = None):\n",
    "\n",
    "    def append_Hbond_235_259_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".protein.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".protein.xtc\"\n",
    "        traj = md.load(location + traj_location,top = location + top_location)\n",
    "        topology = traj.topology\n",
    "        traj = traj.atom_slice(topology.select('resSeq 235 and name NE2 or resSeq 259 and name O'))\n",
    "\n",
    "        distance = []\n",
    "        for chain in [0,2,4,6,8]:\n",
    "            distance.append(md.compute_contacts(traj,[[chain,chain+1]])[0].T)\n",
    "        Hbond_235_259.extend(np.mean(distance,axis=0).T)\n",
    "    Hbond_235_259 = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_Hbond_235_259_data(traj_note)\n",
    "    md_data['Hbond_235_259'] = np.asarray(Hbond_235_259).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Hbond_200_239(md_data = None):\n",
    "\n",
    "    def append_Hbond_200_239_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".protein.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".protein.xtc\"\n",
    "        traj = md.load(location + traj_location,top = location + top_location)\n",
    "        topology = traj.topology\n",
    "        traj = traj.atom_slice(topology.select('resSeq 239 or (resSeq 200 and name O)'))\n",
    "        distance = []\n",
    "        for chain in [0,2,4,6]:\n",
    "            distance.append(md.compute_contacts(traj,[[chain,chain+3]])[0].T)\n",
    "        distance.append(md.compute_contacts(traj,[[8,1]])[0].T)\n",
    "        Hbond_200_239.extend(np.mean(distance,axis=0).T)\n",
    "    Hbond_200_239 = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_Hbond_200_239_data(traj_note)\n",
    "    md_data['Hbond_200_239'] = np.asarray(Hbond_200_239).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Hbond_200_243(md_data = None):\n",
    "\n",
    "    def append_Hbond_200_243_data(traj_note,location = '/media/scottzhuang/data/MD/', skip=10):\n",
    "        top_location = traj_note + '/' + traj_note + \".protein.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".protein.xtc\"\n",
    "        traj = md.load(location + traj_location,top = location + top_location)\n",
    "        topology = traj.topology\n",
    "        traj = traj.atom_slice(topology.select('resSeq 243 or (resSeq 200 and name O)'))\n",
    "        distance = []\n",
    "        for chain in [0,2,4,6]:\n",
    "            distance.append(md.compute_contacts(traj,[[chain,chain+3]])[0].T)\n",
    "        distance.append(md.compute_contacts(traj,[[8,1]])[0].T)\n",
    "        Hbond_200_243.extend(np.mean(distance,axis=0).T)\n",
    "    Hbond_200_243 = []\n",
    "    for traj_note in traj_notes:\n",
    "        append_Hbond_200_243_data(traj_note)\n",
    "    md_data['Hbond_200_243'] = np.asarray(Hbond_200_243).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Hbond_water_200_239(md_data = None):\n",
    "    def add_hbond_data(traj_note,location = '/media/scottzhuang/data/MD/'):\n",
    "        hbond_data_200 = pd.read_csv(location + traj_note + '/resid200_water_hbond.csv')\n",
    "        hbond_data_239 = pd.read_csv(location + traj_note + '/resid239_water_hbond.csv')\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        n_frames = md.load(location + traj_location,top = location + top_location).n_frames\n",
    "        for time in range(0,n_frames*10000,10000):            \n",
    "            hbond200_set = set(hbond_data_200[(hbond_data_200['donor_resid'] == 200) & (hbond_data_200['time'] == time)]['acceptor_resid']).union(set(hbond_data_200[(hbond_data_200['acceptor_resid'] == 200) & (hbond_data_200['time'] == time)]['donor_resid']))\n",
    "            hbond239_set = set(hbond_data_239[(hbond_data_239['donor_resid'] == 239) & (hbond_data_239['time'] == time)]['acceptor_resid']).union(set(hbond_data_239[(hbond_data_239['acceptor_resid'] == 239) & (hbond_data_239['time'] == time)]['donor_resid']))\n",
    "            hbond_resid_data.append(len(hbond200_set.intersection(hbond239_set)))\n",
    "    hbond_resid_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        add_hbond_data(traj_note)\n",
    "    md_data['hbond_water_200_239'] = hbond_resid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Hbond_water_200_243(md_data = None):\n",
    "    def add_hbond_data(traj_note,location = '/media/scottzhuang/data/MD/'):\n",
    "        hbond_data_200 = pd.read_csv(location + traj_note + '/resid200_water_hbond.csv')\n",
    "        hbond_data_243 = pd.read_csv(location + traj_note + '/resid243_water_hbond.csv')\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        n_frames = md.load(location + traj_location,top = location + top_location).n_frames\n",
    "        for time in range(0,n_frames*10000,10000):\n",
    "            hbond200_set = set(hbond_data_200[(hbond_data_200['donor_resid'] == 200) & (hbond_data_200['time'] == time)]['acceptor_resid']).union(set(hbond_data_200[(hbond_data_200['acceptor_resid'] == 200) & (hbond_data_200['time'] == time)]['donor_resid']))\n",
    "            hbond243_set = set(hbond_data_243[(hbond_data_243['donor_resid'] == 243) & (hbond_data_243['time'] == time)]['acceptor_resid']).union(set(hbond_data_243[(hbond_data_243['acceptor_resid'] == 243) & (hbond_data_243['time'] == time)]['donor_resid']))\n",
    "            hbond_resid_data.append(len(hbond200_set.intersection(hbond243_set)))\n",
    "    hbond_resid_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        add_hbond_data(traj_note)\n",
    "    md_data['hbond_water_200_243'] = hbond_resid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_water_bridge_200_243_data(md_data = None):\n",
    "    def add_water_bridge_data(traj_note,location = '/media/scottzhuang/data/MD/',skip=10):\n",
    "        water_bridge_dataframe = pd.read_csv(location + traj_note + '/resid200_243_water_bridge.csv')\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        n_frames = md.load(location + traj_location,top = location + top_location).n_frames\n",
    "        for time in range(0,n_frames*10000,10000):\n",
    "            water_bridge_data.append(len(water_bridge_dataframe[water_bridge_dataframe['time'] == time]))\n",
    "    water_bridge_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        add_water_bridge_data(traj_note)\n",
    "    md_data['water_bridge_200_243'] = water_bridge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_water_bridge_200_239_data(md_data = None):\n",
    "    def add_water_bridge_data(traj_note,location = '/media/scottzhuang/data/MD/',skip=10):\n",
    "        water_bridge_dataframe = pd.read_csv(location + traj_note + '/resid200_239_water_bridge.csv')\n",
    "        top_location = traj_note + '/' + traj_note + \".ca.gro\"\n",
    "        traj_location = traj_note + '/' + traj_note + \".skip\" + str(skip) + \".ca.xtc\"\n",
    "        n_frames = md.load(location + traj_location,top = location + top_location).n_frames\n",
    "        for time in range(0,n_frames*10000,10000):\n",
    "            water_bridge_data.append(len(water_bridge_dataframe[water_bridge_dataframe['time'] == time]))\n",
    "    water_bridge_data = []\n",
    "    for traj_note in traj_notes:\n",
    "        add_water_bridge_data(traj_note)\n",
    "    md_data['water_bridge_200_239'] = water_bridge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_water_bridge_200_243_data(md_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_water_bridge_200_239_data(md_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_Hbond_water_200_239(md_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_Hbond_water_200_243(md_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster_data(md_data = None):\n",
    "    cluster_index = []\n",
    "    def add_cluster_data(traj_note,location = '/media/scottzhuang/data/MD/',skip=10):\n",
    "        cluster_data = pd.read_pickle(location + traj_note + '/ward_cluster_labels.pickle')\n",
    "        cluster_index.extend(cluster_data)\n",
    "    for traj_note in traj_notes:\n",
    "        add_cluster_data(traj_note)\n",
    "    md_data['cluster_index'] = cluster_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_cluster_data(md_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#md_data = create_md_dataframe()\n",
    "#create_metadata(md_data= md_data)\n",
    "md_data = pd.read_csv(\"glic_gating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_data.to_csv(\"glic_gating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 5NJY_pH70_md1, simulation runs 1030 ns.\n",
      "In 5NJY_pH70_md2, simulation runs 750 ns.\n",
      "In 5NJY_pH70_md3, simulation runs 810 ns.\n",
      "In 5NJY_F238L_pH70_md1, simulation runs 540 ns.\n",
      "In 5NJY_F238L_pH70_md2, simulation runs 680 ns.\n",
      "In 5NJY_F238L_pH70_md3, simulation runs 720 ns.\n",
      "In 5NJY_I233T_pH70_md4, simulation runs 730 ns.\n",
      "In 5NJY_I233T_pH70_md2, simulation runs 590 ns.\n",
      "In 5NJY_I233T_pH70_md3, simulation runs 820 ns.\n",
      "In 5NJY_F238LI233T_pH70_md1, simulation runs 830 ns.\n",
      "In 5NJY_F238LI233T_pH70_md2, simulation runs 800 ns.\n",
      "In 5NJY_F238LI233T_pH70_md3, simulation runs 880 ns.\n",
      "In 5NJY_pH46_md1, simulation runs 780 ns.\n",
      "In 5NJY_pH46_md2, simulation runs 1060 ns.\n",
      "In 5NJY_pH46_md3, simulation runs 1030 ns.\n",
      "In 5NJY_F238L_pH46_md1, simulation runs 930 ns.\n",
      "In 5NJY_F238L_pH46_md2, simulation runs 950 ns.\n",
      "In 5NJY_F238L_pH46_md3, simulation runs 1090 ns.\n",
      "In 5NJY_I233T_pH46_md1, simulation runs 810 ns.\n",
      "In 5NJY_I233T_pH46_md2, simulation runs 870 ns.\n",
      "In 5NJY_I233T_pH46_md3, simulation runs 980 ns.\n",
      "In 5NJY_F238LI233T_pH46_md1, simulation runs 790 ns.\n",
      "In 5NJY_F238LI233T_pH46_md2, simulation runs 950 ns.\n",
      "In 5NJY_F238LI233T_pH46_md3, simulation runs 960 ns.\n",
      "In 4HFI_pH46_md1, simulation runs 1100 ns.\n",
      "In 4HFI_pH46_md2, simulation runs 1100 ns.\n",
      "In 4HFI_pH46_md3, simulation runs 1070 ns.\n",
      "In 4HFI_F238L_pH46_md1, simulation runs 1040 ns.\n",
      "In 4HFI_F238L_pH46_md2, simulation runs 1010 ns.\n",
      "In 4HFI_F238L_pH46_md3, simulation runs 1040 ns.\n",
      "In 4HFI_I233T_pH46_md1, simulation runs 1030 ns.\n",
      "In 4HFI_I233T_pH46_md2, simulation runs 1030 ns.\n",
      "In 4HFI_I233T_pH46_md3, simulation runs 1030 ns.\n",
      "In 4HFI_F238LI233T_pH46_md1, simulation runs 1060 ns.\n",
      "In 4HFI_F238LI233T_pH46_md2, simulation runs 1010 ns.\n",
      "In 4HFI_F238LI233T_pH46_md3, simulation runs 1120 ns.\n",
      "In 4NPQ_pH70_md5, simulation runs 840 ns.\n",
      "In 4NPQ_pH70_md6, simulation runs 940 ns.\n",
      "In 4NPQ_pH70_md7, simulation runs 1050 ns.\n",
      "In 4NPQ_F238L_pH70_md3, simulation runs 830 ns.\n",
      "In 4NPQ_F238L_pH70_md4, simulation runs 990 ns.\n",
      "In 4NPQ_F238L_pH70_md5, simulation runs 960 ns.\n",
      "In 4NPQ_I233T_pH70_md3, simulation runs 890 ns.\n",
      "In 4NPQ_I233T_pH70_md4, simulation runs 980 ns.\n",
      "In 4NPQ_I233T_pH70_md5, simulation runs 1050 ns.\n",
      "In 4NPQ_F238LI233T_pH70_md3, simulation runs 880 ns.\n",
      "In 4NPQ_F238LI233T_pH70_md4, simulation runs 920 ns.\n",
      "In 4NPQ_F238LI233T_pH70_md5, simulation runs 1010 ns.\n"
     ]
    }
   ],
   "source": [
    "md_data = create_md_dataframe()\n",
    "create_metadata(md_data= md_data)\n",
    "create_system_notation(md_data = md_data)\n",
    "create_rmsd_data(md_data= md_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pca_data(md_data = md_data)\n",
    "create_cppca_data(md_data= md_data)\n",
    "create_domain_twist_data(md_data= md_data)\n",
    "#create_hole_data(md_data= md_data)\n",
    "create_cppca_data_2(md_data)\n",
    "#create_hbond_data(md_data=md_data)\n",
    "create_hydration_profile(md_data)\n",
    "create_hydration_profile_2(md_data)\n",
    "create_hydration_profile_3(md_data)\n",
    "create_hydration_profile_4(md_data)\n",
    "create_hydration_profile_5(md_data)\n",
    "create_hydration_profile_7(md_data)\n",
    "create_pore_profile(md_data)\n",
    "create_helix_tilt_data(md_data)\n",
    "create_helix_twist_data(md_data)\n",
    "create_beta_expansion(md_data)\n",
    "create_M2_radius(md_data)\n",
    "create_ECD_radius(md_data)\n",
    "create_M2_M1_distance(md_data)\n",
    "create_M1_kink(md_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_data.to_csv(\"glic_gating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'MD_name', 'pH', 'replicate', 'traj_time', 'system',\n",
       "       'rmsd', 'wholepca_pc1', 'wholepca_pc2', 'ecd_pc1', 'tmd_pc1',\n",
       "       'domain twist', 'ecd_pc2', 'tmd_pc2', 'hydration_data',\n",
       "       'hydration_data_235_3a', 'hydration_data_233_3a',\n",
       "       'hydration_data_238_3a', 'hydration_data_226_3a',\n",
       "       'hydration_data_240_3a', 'pore_profile_222', 'pore_profile_226',\n",
       "       'pore_profile_230', 'pore_profile_233', 'pore_profile_237',\n",
       "       'pore_profile_240', 'helix tilt angle', 'helix twist angle',\n",
       "       'beta_expansion', 'M2_radius', 'ECD_radius', 'M2_M1_distance',\n",
       "       'M1_kink', 'Hbond_235_259', 'Hbond_200_239', 'Hbond_200_243',\n",
       "       'hydration_data_m123', 'hbond_water_200_239', 'hbond_water_200_243',\n",
       "       'water_bridge_200_243', 'water_bridge_200_239', 'hbond(235, 259)',\n",
       "       'hbond(239, 200)', 'hbond(243, 200)', 'hbond_200_239', 'hbond_200_243',\n",
       "       'hydration_data_intra', 'hydration_data_inter', 'hbond_235_239',\n",
       "       'hbond_235_239_acceptor', 'hbond_235_239_donor'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_data.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepchem",
   "language": "python",
   "name": "deepchem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
