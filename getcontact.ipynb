{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import mdtraj as md\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.cluster.hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "import pandas as pd\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import MDAnalysis as mda\n",
    "from statistics import mode\n",
    "import ast\n",
    "import msmexplorer as msme\n",
    "from msmbuilder.utils import load,dump\n",
    "import itertools\n",
    "from msmbuilder.featurizer import ContactFeaturizer\n",
    "from msmbuilder.featurizer import DihedralFeaturizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#XRD Ensemble\n",
    "#28 4NPQ\n",
    "#18 4HFI\n",
    "import seaborn as sns\n",
    "import ptitprince as pt\n",
    "sns.set(style=\"whitegrid\",font_scale=1.4)\n",
    "import matplotlib.collections as clt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_notes =  [\n",
    "              '4HFI_pH46_md4','4HFI_pH46_md5','4HFI_pH46_md6',\n",
    "        '4HFI_pH46_md7','4HFI_pH46_md8','4HFI_pH46_md9',\n",
    "                '4HFI_F238L_pH46_md7','4HFI_F238L_pH46_md8','4HFI_F238L_pH46_md9',\n",
    "        '4HFI_F238L_pH46_md4','4HFI_F238L_pH46_md5','4HFI_F238L_pH46_md6',\n",
    "              '4HFI_I233T_pH46_md4','4HFI_I233T_pH46_md5','4HFI_I233T_pH46_md6',\n",
    "        '4HFI_I233T_pH46_md7','4HFI_I233T_pH46_md8','4HFI_I233T_pH46_md9',\n",
    "                '4HFI_F238LI233T_pH46_md4','4HFI_F238LI233T_pH46_md5','4HFI_F238LI233T_pH46_md6',\n",
    "            '4HFI_F238LI233T_pH46_md7','4HFI_F238LI233T_pH46_md8','4HFI_F238LI233T_pH46_md9',\n",
    "            '5NJY_pH70_md1','5NJY_pH70_md2','5NJY_pH70_md3',\n",
    "              '5NJY_F238L_pH70_md1','5NJY_F238L_pH70_md2','5NJY_F238L_pH70_md3',\n",
    "              '5NJY_I233T_pH70_md4','5NJY_I233T_pH70_md2','5NJY_I233T_pH70_md3',\n",
    "              '5NJY_F238LI233T_pH70_md1','5NJY_F238LI233T_pH70_md2','5NJY_F238LI233T_pH70_md3',\n",
    "              '5NJY_pH46_md1','5NJY_pH46_md2','5NJY_pH46_md3',\n",
    "              '5NJY_F238L_pH46_md1','5NJY_F238L_pH46_md2','5NJY_F238L_pH46_md3',\n",
    "              '5NJY_I233T_pH46_md1','5NJY_I233T_pH46_md2','5NJY_I233T_pH46_md3',\n",
    "              '5NJY_F238LI233T_pH46_md1','5NJY_F238LI233T_pH46_md2','5NJY_F238LI233T_pH46_md3',\n",
    "                '4HFI_F238A_pH46_md1','4HFI_F238A_pH46_md2','4HFI_F238A_pH46_md3'\n",
    "                ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_intra_inter_flare(traj_note):\n",
    "    for interaction in ['hb','sb','pc','ps','ts','hp']:\n",
    "        with open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.tmd.json', 'r') as f:\n",
    "            flare = json.load(f)\n",
    "            intra_flare={'edges': []}\n",
    "            inter_flare={'edges': []}\n",
    "            intra_flare_dataframe = pd.DataFrame(columns=['frames', 'name1','name2'])\n",
    "            inter_flare_dataframe = pd.DataFrame(columns=['frames', 'name1','name2'])\n",
    "\n",
    "            for i in range (0,len(flare['edges'])):\n",
    "                if (flare['edges'][i]['name1'][0] == flare['edges'][i]['name2'][0]):\n",
    "               # & (flare['edges'][i]['name1'][-3] != ':') & (flare['edges'][i]['name1'][-3] != '3') & (flare['edges'][i]['name2'][-3] != ':') & (flare['edges'][i]['name2'][-3] != '3') :\n",
    "                    flare['edges'][i]['name1'] = flare['edges'][i]['name1'][6:]\n",
    "                    flare['edges'][i]['name2'] = flare['edges'][i]['name2'][6:]\n",
    "#                    if int(flare['edges'][i]['name1']) <= 198:\n",
    "#                        flare['edges'][i]['color'] = 'black'\n",
    "#                    elif int(flare['edges'][i]['name1']) <= 220:\n",
    "#                        flare['edges'][i]['color'] = 'red'\n",
    "#                    elif int(flare['edges'][i]['name1']) <= 245:\n",
    "#                        flare['edges'][i]['color'] = 'blue'\n",
    "#                    elif int(flare['edges'][i]['name1']) <= 265:\n",
    "#                        flare['edges'][i]['color'] = 'green'\n",
    "#                    else:\n",
    "#                        flare['edges'][i]['color'] = 'purple'\n",
    "\n",
    "                    if int(flare['edges'][i]['name1']) == 263:\n",
    "                        flare['edges'][i]['color'] = 'blue'\n",
    "                    if int(flare['edges'][i]['name1']) == 200:\n",
    "                        flare['edges'][i]['color'] = 'red'\n",
    "                    if int(flare['edges'][i]['name1']) == 239:\n",
    "                        flare['edges'][i]['color'] = 'green'\n",
    "                    if int(flare['edges'][i]['name1']) == 243:\n",
    "                        flare['edges'][i]['color'] = 'purple'\n",
    "                    if int(flare['edges'][i]['name2']) == 263:\n",
    "                        flare['edges'][i]['color'] = 'blue'\n",
    "                    if int(flare['edges'][i]['name2']) == 200:\n",
    "                        flare['edges'][i]['color'] = 'red'\n",
    "                    if int(flare['edges'][i]['name2']) == 239:\n",
    "                        flare['edges'][i]['color'] = 'green'\n",
    "                    if int(flare['edges'][i]['name2']) == 243:\n",
    "                        flare['edges'][i]['color'] = 'purple'\n",
    "                    if intra_flare_dataframe[(intra_flare_dataframe['name1'] == flare['edges'][i]['name1']) & (intra_flare_dataframe['name2'] == flare['edges'][i]['name2'])].shape[0] == 0:\n",
    "                        intra_flare['edges'].append(flare['edges'][i])\n",
    "                        intra_flare_dataframe = intra_flare_dataframe.append(flare['edges'][i],ignore_index=True)\n",
    "                    else:\n",
    "                        intra_flare['edges'][intra_flare_dataframe[(intra_flare_dataframe['name1'] == flare['edges'][i]['name1']) & (intra_flare_dataframe['name2'] == flare['edges'][i]['name2'])].index[0]]['frames'].extend(flare['edges'][i]['frames'])\n",
    "\n",
    "                elif (flare['edges'][i]['name1'][0] != flare['edges'][i]['name2'][0]) :\n",
    "                    #& (flare['edges'][i]['name1'][-3] != ':') & (flare['edges'][i]['name1'][-3] != '3') & (flare['edges'][i]['name2'][-3] != ':') & (flare['edges'][i]['name2'][-3] != '3') :\n",
    "                    flare['edges'][i]['name1'] = flare['edges'][i]['name1'][6:]\n",
    "                    flare['edges'][i]['name2'] = flare['edges'][i]['name2'][6:]\n",
    "#                    if int(flare['edges'][i]['name1']) <= 198:\n",
    "#                        flare['edges'][i]['color'] = 'black'\n",
    "#                    elif int(flare['edges'][i]['name1']) <= 220:\n",
    "#                        flare['edges'][i]['color'] = 'red'\n",
    "#                    elif int(flare['edges'][i]['name1']) <= 245:\n",
    "#                        flare['edges'][i]['color'] = 'blue'\n",
    "#                    elif int(flare['edges'][i]['name1']) <= 265:\n",
    "#                        flare['edges'][i]['color'] = 'green'\n",
    "#                    else:\n",
    "#                        flare['edges'][i]['color'] = 'purple'\n",
    "                    if int(flare['edges'][i]['name1']) == 263:\n",
    "                        flare['edges'][i]['color'] = 'blue'\n",
    "                    if int(flare['edges'][i]['name1']) == 200:\n",
    "                        flare['edges'][i]['color'] = 'red'\n",
    "                    if int(flare['edges'][i]['name1']) == 239:\n",
    "                        flare['edges'][i]['color'] = 'green'\n",
    "                    if int(flare['edges'][i]['name1']) == 243:\n",
    "                        flare['edges'][i]['color'] = 'purple'\n",
    "                    if int(flare['edges'][i]['name2']) == 263:\n",
    "                        flare['edges'][i]['color'] = 'blue'\n",
    "                    if int(flare['edges'][i]['name2']) == 200:\n",
    "                        flare['edges'][i]['color'] = 'red'\n",
    "                    if int(flare['edges'][i]['name2']) == 239:\n",
    "                        flare['edges'][i]['color'] = 'green'\n",
    "                    if int(flare['edges'][i]['name2']) == 243:\n",
    "                        flare['edges'][i]['color'] = 'purple'\n",
    "            \n",
    "                    if inter_flare_dataframe[(inter_flare_dataframe['name1'] == flare['edges'][i]['name1']) & (inter_flare_dataframe['name2'] == flare['edges'][i]['name2'])].shape[0] == 0:\n",
    "                        inter_flare['edges'].append(flare['edges'][i])\n",
    "                        inter_flare_dataframe = inter_flare_dataframe.append(flare['edges'][i],ignore_index=True)\n",
    "                    else:\n",
    "                        inter_flare['edges'][inter_flare_dataframe[(inter_flare_dataframe['name1'] == flare['edges'][i]['name1']) & (inter_flare_dataframe['name2'] == flare['edges'][i]['name2'])].index[0]]['frames'].extend(flare['edges'][i]['frames'])\n",
    "        for i in range (0,len(intra_flare['edges'])):\n",
    "            intra_flare['edges'][i]['frames'] = list(set(intra_flare['edges'][i]['frames']))\n",
    "        for i in range (0,len(inter_flare['edges'])):\n",
    "            inter_flare['edges'][i]['frames'] = list(set(inter_flare['edges'][i]['frames']))\n",
    "\n",
    "        with open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.inter.tmd.json', 'w') as f:\n",
    "            json.dump(inter_flare, f)\n",
    "        with open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.intra.tmd.json', 'w') as f:\n",
    "            json.dump(intra_flare, f)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "Parallel(n_jobs=num_cores)(delayed(make_intra_inter_flare)(traj_note) for traj_note in traj_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_freq_chain(traj_note):\n",
    "    for interaction in ['hb','sb','pc','ps','ts','hp']:\n",
    "        freq_data = pd.read_csv('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.tsv',sep='\\s+',header=None,skiprows=2,names=['residue1','residue2','contact_freq'])\n",
    "        freq_data['chain1'] = freq_data['residue1'].apply(lambda x: x[x.find(':')-1])\n",
    "        freq_data['chain2'] = freq_data['residue2'].apply(lambda x: x[x.find(':')-1])\n",
    "        freq_data['residue1'] = freq_data['residue1'].apply(lambda x: x[x.find(':')+5:])\n",
    "        freq_data['residue2'] = freq_data['residue2'].apply(lambda x: x[x.find(':')+5:])\n",
    "        freq_data.to_csv('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.chain.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "Parallel(n_jobs=num_cores)(delayed(recover_freq_chain)(traj_note) for traj_note in traj_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_intra_inter_freq(traj_note):\n",
    "    for interaction in ['hb','sb','pc','ps','ts','hp']:\n",
    "        freq_data = pd.read_csv('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.tsv',sep='\\s+',header=None,skiprows=2,names=['residue1','residue2','contact_freq'])\n",
    "#        freq_data[freq_data.residue1.apply(lambda x: x[x.find(':')-1]) == freq_data.residue2.apply(lambda x: x[x.find(':')-1])].to_csv('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.intra.tsv')\n",
    "#        freq_data[freq_data.residue1.apply(lambda x: x[x.find(':')-1]) != freq_data.residue2.apply(lambda x: x[x.find(':')-1])].to_csv('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.inter.tsv')\n",
    "        with open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.intra.tsv', 'w') as output_file:\n",
    "            output_file.write(open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.tsv').readlines()[0])\n",
    "            output_file.write(open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.tsv').readlines()[1])\n",
    "\n",
    "            for index,(res1, res2, frequency) in freq_data[freq_data.residue1.apply(lambda x: x[x.find(':')-1]) == freq_data.residue2.apply(lambda x: x[x.find(':')-1])][['residue1','residue2','contact_freq']].iterrows():\n",
    "                output_file.write('\\t'.join([res1, res2, \"%.3f\" % frequency]) + \"\\n\")\n",
    "        with open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.inter.tsv', 'w') as output_file:\n",
    "            output_file.write(open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.tsv').readlines()[0])\n",
    "            output_file.write(open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.tsv').readlines()[1])\n",
    "            for index,(res1, res2, frequency) in freq_data[freq_data.residue1.apply(lambda x: x[x.find(':')-1]) != freq_data.residue2.apply(lambda x: x[x.find(':')-1])][['residue1','residue2','contact_freq']].iterrows():\n",
    "                output_file.write('\\t'.join([res1, res2, \"%.3f\" % frequency]) + \"\\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "Parallel(n_jobs=num_cores)(delayed(make_intra_inter_freq)(traj_note) for traj_note in traj_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_notes = ['4HFI_pH46_ethanol_md1','4HFI_pH46_ethanol_md2','4HFI_pH46_ethanol_md3',\n",
    "                '4HFI_F238L_pH46_ethanol_md1','4HFI_F238L_pH46_ethanol_md4','4HFI_F238L_pH46_ethanol_md5','4HFI_F238L_pH46_ethanol_md6',\n",
    "                '4HFI_F238LI233T_pH46_ethanol_md1','4HFI_F238LI233T_pH46_ethanol_md2','4HFI_F238LI233T_pH46_ethanol_md3',\n",
    "                '4HFI_F238LI233T_pH46_ethanol_md4','4HFI_F238LI233T_pH46_ethanol_md5','4HFI_F238LI233T_pH46_ethanol_md6',\n",
    "                '4HFI_I233T_pH46_ethanol_md1','4HFI_I233T_pH46_ethanol_md2','4HFI_I233T_pH46_ethanol_md3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ethanol_flare(traj_note):\n",
    "    for interaction in ['hp','hb']:\n",
    "        with open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.lig.json', 'r') as f:\n",
    "            flare_frames = pd.DataFrame(columns=['resid','frames'])\n",
    "\n",
    "            flare = json.load(f)\n",
    "            for i in range (0,len(flare['edges'])):\n",
    "                flare['edges'][i]['name1'] = 'X' + flare['edges'][i]['name1'][1:]\n",
    "                flare['edges'][i]['name2'] = 'X:LIG:0'\n",
    "                if flare['edges'][i]['name1'] in list(flare_frames['resid']):\n",
    "\n",
    "        #            flare_frames.loc[flare_frames.resid == flare['edges'][i]['name1'],'frames'].values[0].extend([0])\n",
    "                    frames_list = flare_frames.loc[flare_frames.resid == flare['edges'][i]['name1'],'frames'].values[0]\n",
    "                    frames_list.extend(flare['edges'][i]['frames'])\n",
    "                    flare_frames.loc[flare_frames.resid == flare['edges'][i]['name1'],'frames'].values[0] = frames_list\n",
    "        #            flare_frames.loc[flare_frames.resid == flare['edges'][i]['name1'],'frames'] = flare_frames.loc[flare_frames.resid == flare['edges'][i]['name1'],'frames'].values.extend(flare['edges'][i]['frames'])\n",
    "                else:\n",
    "                    flare_frames = flare_frames.append({'resid':flare['edges'][i]['name1'], 'frames':flare['edges'][i]['frames']}, ignore_index=True)\n",
    "            for i in range (0,len(flare['edges'])):\n",
    "                flare['edges'][i]['frames'] = flare_frames[flare_frames.resid == flare['edges'][i]['name1']]['frames'].values[0]        \n",
    "        with open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.lig.ethanol.json', 'w') as f:\n",
    "            json.dump(flare, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "Parallel(n_jobs=num_cores)(delayed(make_ethanol_flare_chain)(traj_note) for traj_note in traj_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ethanol_flare_chain(traj_note):\n",
    "    for interaction in ['hp','hb']:\n",
    "        with open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.lig.json', 'r') as f:\n",
    "            flare_frames = pd.DataFrame(columns=['resid','frames'])\n",
    "\n",
    "            flare = json.load(f)\n",
    "            for i in range (0,len(flare['edges'])):\n",
    "                flare['edges'][i]['name2'] = 'X:LIG:0'\n",
    "                if flare['edges'][i]['name1'] in list(flare_frames['resid']):\n",
    "\n",
    "        #            flare_frames.loc[flare_frames.resid == flare['edges'][i]['name1'],'frames'].values[0].extend([0])\n",
    "                    frames_list = flare_frames.loc[flare_frames.resid == flare['edges'][i]['name1'],'frames'].values[0]\n",
    "                    frames_list.extend(flare['edges'][i]['frames'])\n",
    "                    flare_frames.loc[flare_frames.resid == flare['edges'][i]['name1'],'frames'].values[0] = frames_list\n",
    "        #            flare_frames.loc[flare_frames.resid == flare['edges'][i]['name1'],'frames'] = flare_frames.loc[flare_frames.resid == flare['edges'][i]['name1'],'frames'].values.extend(flare['edges'][i]['frames'])\n",
    "                else:\n",
    "                    flare_frames = flare_frames.append({'resid':flare['edges'][i]['name1'], 'frames':flare['edges'][i]['frames']}, ignore_index=True)\n",
    "            for i in range (0,len(flare['edges'])):\n",
    "                flare['edges'][i]['frames'] = flare_frames[flare_frames.resid == flare['edges'][i]['name1']]['frames'].values[0]        \n",
    "        with open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.lig.ethanol.chain.json', 'w') as f:\n",
    "            json.dump(flare, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ethanol_freq(traj_note):\n",
    "    for interaction in ['hb', 'hp']:\n",
    "        freq_data = pd.read_csv('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.lig.tsv',sep='\\s+',header=None,skiprows=2,names=['residue1','residue2','contact_freq'])\n",
    "        freq_data.residue2 = 'X:LIG:0'\n",
    "        freq_data.residue1 = 'X' + freq_data['residue1'].apply(lambda x: x[x.find(':'):])\n",
    "        with open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.lig.new.tsv', 'w') as output_file:\n",
    "            output_file.write(open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.tsv').readlines()[0])\n",
    "            output_file.write(open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.tsv').readlines()[1])\n",
    "\n",
    "            for index,(res1, res2, frequency) in freq_data[['residue1','residue2','contact_freq']].iterrows():\n",
    "                output_file.write('\\t'.join([res1, res2, \"%.3f\" % frequency]) + \"\\n\")\n",
    "       \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "Parallel(n_jobs=num_cores)(delayed(make_ethanol_freq)(traj_note) for traj_note in traj_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ethanol_freq_resid_stack(traj_note):\n",
    "    for interaction in ['hb', 'hp']:\n",
    "        new_freq_data = pd.DataFrame(columns=['residue1','residue2','contact_freq'])\n",
    "        freq_data = pd.read_csv('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.lig.new.tsv',sep='\\s+',header=None,skiprows=2,names=['residue1','residue2','contact_freq'])\n",
    "        residues = set(freq_data.residue1)\n",
    "        for residue in residues:\n",
    "            new_freq_data = new_freq_data.append({'residue1':residue,'residue2':'X:LIG:0','contact_freq':sum(freq_data[freq_data.residue1==residue]['contact_freq'])},ignore_index=True)\n",
    "        with open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.lig.new.resid.tsv', 'w') as output_file:\n",
    "            output_file.write(open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.tsv').readlines()[0])\n",
    "            output_file.write(open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.tsv').readlines()[1])\n",
    "\n",
    "            for index,(res1, res2, frequency) in new_freq_data[['residue1','residue2','contact_freq']].iterrows():\n",
    "                output_file.write('\\t'.join([res1, res2, \"%.3f\" % frequency]) + \"\\n\")\n",
    "       \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "Parallel(n_jobs=num_cores)(delayed(make_ethanol_freq_resid_stack)(traj_note) for traj_note in traj_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ethanol_freq_resid_stack_40(traj_note):\n",
    "    for interaction in ['hb', 'hp']:\n",
    "        new_freq_data = pd.DataFrame(columns=['residue1','residue2','contact_freq'])\n",
    "        freq_data = pd.read_csv('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.lig.40.tsv',sep='\\s+',header=None,skiprows=2,names=['residue1','residue2','contact_freq'])\n",
    "        residues = set(freq_data.residue1)\n",
    "        for residue in residues:\n",
    "            new_freq_data = new_freq_data.append({'residue1':residue,'residue2':'X:LIG:0','contact_freq':sum(freq_data[freq_data.residue1==residue]['contact_freq'])},ignore_index=True)\n",
    "        with open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.lig.resid.40.tsv', 'w') as output_file:\n",
    "            output_file.write(open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.lig.40.tsv').readlines()[0])\n",
    "            output_file.write(open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.lig.40.tsv').readlines()[1])\n",
    "\n",
    "            for index,(res1, res2, frequency) in new_freq_data[['residue1','residue2','contact_freq']].iterrows():\n",
    "                output_file.write('\\t'.join([res1, res2, \"%.3f\" % frequency]) + \"\\n\")\n",
    "       \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "Parallel(n_jobs=num_cores)(delayed(make_ethanol_freq_resid_stack_40)(traj_note) for traj_note in traj_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_freq_resid_stack(traj_note):\n",
    "    for interaction in ['hb','sb','pc','ps','ts','hp']:\n",
    "        freq_data = pd.read_csv('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.inter.tsv',sep='\\s+',header=None,skiprows=2,names=['residue1','residue2','contact_freq'])\n",
    "#        freq_data[freq_data.residue1.apply(lambda x: x[x.find(':')-1]) == freq_data.residue2.apply(lambda x: x[x.find(':')-1])].to_csv('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.intra.tsv')\n",
    "#        freq_data[freq_data.residue1.apply(lambda x: x[x.find(':')-1]) != freq_data.residue2.apply(lambda x: x[x.find(':')-1])].to_csv('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.inter.tsv')\n",
    "        freq_data.residue1 = 'X' + freq_data['residue1'].apply(lambda x: x[x.find(':'):])\n",
    "        freq_data.residue2 = 'X' + freq_data['residue2'].apply(lambda x: x[x.find(':'):])\n",
    "\n",
    "        new_freq_data = pd.DataFrame(columns=['residue1','residue2','contact_freq'])\n",
    "\n",
    "        residues_pairs = set((list[0] + '_' + list[1]) for list in np.asarray(freq_data))\n",
    "        for residue_pair in residues_pairs:\n",
    "            new_freq_data = new_freq_data.append({'residue1':residue_pair[:residue_pair.find('_')],'residue2':residue_pair[residue_pair.find('_')+1:],'contact_freq':sum(freq_data[(freq_data.residue1 == residue_pair[:residue_pair.find('_')]) & (freq_data.residue2 == residue_pair[residue_pair.find('_')+1:]) ]['contact_freq'])/5},ignore_index=True)    \n",
    "        with open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.inter.resid.tsv', 'w') as output_file:\n",
    "            output_file.write(open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.inter.tsv').readlines()[0])\n",
    "            output_file.write(open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.inter.tsv').readlines()[1])\n",
    "            for index,(res1, res2, frequency) in new_freq_data[['residue1','residue2','contact_freq']].iterrows():\n",
    "                output_file.write('\\t'.join([res1, res2, \"%.3f\" % frequency]) + \"\\n\")\n",
    "\n",
    "        freq_data = pd.read_csv('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.intra.tsv',sep='\\s+',header=None,skiprows=2,names=['residue1','residue2','contact_freq'])\n",
    "#        freq_data[freq_data.residue1.apply(lambda x: x[x.find(':')-1]) == freq_data.residue2.apply(lambda x: x[x.find(':')-1])].to_csv('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.intra.tsv')\n",
    "#        freq_data[freq_data.residue1.apply(lambda x: x[x.find(':')-1]) != freq_data.residue2.apply(lambda x: x[x.find(':')-1])].to_csv('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.inter.tsv')\n",
    "        freq_data.residue1 = 'X' + freq_data['residue1'].apply(lambda x: x[x.find(':'):])\n",
    "        freq_data.residue2 = 'X' + freq_data['residue2'].apply(lambda x: x[x.find(':'):])\n",
    "        new_freq_data = pd.DataFrame(columns=['residue1','residue2','contact_freq'])\n",
    "\n",
    "    \n",
    "        residues_pairs = set((list[0] + '_' + list[1]) for list in np.asarray(freq_data))\n",
    "        for residue_pair in residues_pairs:\n",
    "            new_freq_data = new_freq_data.append({'residue1':residue_pair[:residue_pair.find('_')],'residue2':residue_pair[residue_pair.find('_')+1:],'contact_freq':sum(freq_data[(freq_data.residue1 == residue_pair[:residue_pair.find('_')]) & (freq_data.residue2 == residue_pair[residue_pair.find('_')+1:]) ]['contact_freq'])/5},ignore_index=True)    \n",
    "        with open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.intra.resid.tsv', 'w') as output_file:\n",
    "            output_file.write(open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.intra.tsv').readlines()[0])\n",
    "            output_file.write(open('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.intra.tsv').readlines()[1])\n",
    "            for index,(res1, res2, frequency) in new_freq_data[['residue1','residue2','contact_freq']].iterrows():\n",
    "                output_file.write('\\t'.join([res1, res2, \"%.3f\" % frequency]) + \"\\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "Parallel(n_jobs=num_cores)(delayed(make_freq_resid_stack)(traj_note) for traj_note in traj_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_freq_resid_rep_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_notess =  [\n",
    "              ['4HFI_pH46_md4','4HFI_pH46_md5','4HFI_pH46_md6'],\n",
    "        ['4HFI_F238L_pH46_md4','4HFI_F238L_pH46_md5','4HFI_F238L_pH46_md6'],\n",
    "              ['4HFI_I233T_pH46_md4','4HFI_I233T_pH46_md5','4HFI_I233T_pH46_md6'],\n",
    "            ['4HFI_F238LI233T_pH46_md7','4HFI_F238LI233T_pH46_md8','4HFI_F238LI233T_pH46_md9']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_notess =  [\n",
    "              ['4HFI_pH46_md4','4HFI_pH46_md5','4HFI_pH46_md6'],\n",
    "        ['4HFI_pH46_md7','4HFI_pH46_md8','4HFI_pH46_md9'],\n",
    "                ['4HFI_F238L_pH46_md7','4HFI_F238L_pH46_md8','4HFI_F238L_pH46_md9'],\n",
    "        ['4HFI_F238L_pH46_md4','4HFI_F238L_pH46_md5','4HFI_F238L_pH46_md6'],\n",
    "              ['4HFI_I233T_pH46_md4','4HFI_I233T_pH46_md5','4HFI_I233T_pH46_md6'],\n",
    "        ['4HFI_I233T_pH46_md7','4HFI_I233T_pH46_md8','4HFI_I233T_pH46_md9'],\n",
    "                ['4HFI_F238LI233T_pH46_md4','4HFI_F238LI233T_pH46_md5','4HFI_F238LI233T_pH46_md6'],\n",
    "            ['4HFI_F238LI233T_pH46_md7','4HFI_F238LI233T_pH46_md8','4HFI_F238LI233T_pH46_md9'],\n",
    "            ['5NJY_pH70_md1','5NJY_pH70_md2','5NJY_pH70_md3'],\n",
    "              ['5NJY_F238L_pH70_md1','5NJY_F238L_pH70_md2','5NJY_F238L_pH70_md3'],\n",
    "              ['5NJY_I233T_pH70_md4','5NJY_I233T_pH70_md2','5NJY_I233T_pH70_md3'],\n",
    "              ['5NJY_F238LI233T_pH70_md1','5NJY_F238LI233T_pH70_md2','5NJY_F238LI233T_pH70_md3'],\n",
    "              ['5NJY_pH46_md1','5NJY_pH46_md2','5NJY_pH46_md3'],\n",
    "              ['5NJY_F238L_pH46_md1','5NJY_F238L_pH46_md2','5NJY_F238L_pH46_md3'],\n",
    "              ['5NJY_I233T_pH46_md1','5NJY_I233T_pH46_md2','5NJY_I233T_pH46_md3'],\n",
    "              ['5NJY_F238LI233T_pH46_md1','5NJY_F238LI233T_pH46_md2','5NJY_F238LI233T_pH46_md3'],\n",
    "                ['4HFI_F238A_pH46_md1','4HFI_F238A_pH46_md2','4HFI_F238A_pH46_md3']\n",
    "                ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_freq_resid_rep_avg(traj_notes):\n",
    "    for interaction in ['hb','sb','pc','ps','ts','hp']:\n",
    "        new_inter_freq_data = pd.DataFrame(columns=['residue1','residue2','contact_freq'])\n",
    "\n",
    "        for traj_note in traj_notes:\n",
    "            freq_data = pd.read_csv('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.inter.resid.tsv',sep='\\s+',header=None,skiprows=2,names=['residue1','residue2','contact_freq'])\n",
    "#                residues_pairs = set((list[0] + '_' + list[1]) for list in np.asarray(freq_data))\n",
    "            for index, row in freq_data.iterrows():\n",
    "#            for residue_pair in residues_pairs:\n",
    "                if new_inter_freq_data[(new_inter_freq_data.residue1 == row['residue1']) & (new_inter_freq_data.residue2 == row['residue2'])].shape[0] == 0:\n",
    "                    new_inter_freq_data = new_inter_freq_data.append({'residue1':row['residue1'],'residue2':row['residue2'],'contact_freq':row['contact_freq']/len(traj_notes)},ignore_index=True)\n",
    "                else:\n",
    "                    new_inter_freq_data.loc[(new_inter_freq_data.residue1 == row['residue1']) & (new_inter_freq_data.residue2 == row['residue2']),'contact_freq'] += row['contact_freq']/len(traj_notes)\n",
    "        with open('/home/scottzhuang/pdc/'+ traj_notes[0] +'/getcontact/'+ traj_notes[0] +'.'+ interaction +'.freq.inter.resid.rep_avg.tsv', 'w') as output_file:\n",
    "            output_file.write(open('/home/scottzhuang/pdc/'+ traj_notes[0] +'/getcontact/'+ traj_notes[0] +'.'+ interaction +'.freq.inter.tsv').readlines()[0])\n",
    "            output_file.write(open('/home/scottzhuang/pdc/'+ traj_notes[0] +'/getcontact/'+ traj_notes[0] +'.'+ interaction +'.freq.inter.tsv').readlines()[1])\n",
    "            for index,(res1, res2, frequency) in new_inter_freq_data[['residue1','residue2','contact_freq']].iterrows():\n",
    "                output_file.write('\\t'.join([res1, res2, \"%.3f\" % frequency]) + \"\\n\")\n",
    "\n",
    "        new_intra_freq_data = pd.DataFrame(columns=['residue1','residue2','contact_freq'])\n",
    "\n",
    "        for traj_note in traj_notes:\n",
    "            freq_data = pd.read_csv('/home/scottzhuang/pdc/'+ traj_note +'/getcontact/'+ traj_note +'.'+ interaction +'.freq.intra.resid.tsv',sep='\\s+',header=None,skiprows=2,names=['residue1','residue2','contact_freq'])\n",
    "#                residues_pairs = set((list[0] + '_' + list[1]) for list in np.asarray(freq_data))\n",
    "            for index, row in freq_data.iterrows():\n",
    "#            for residue_pair in residues_pairs:\n",
    "                if new_intra_freq_data[(new_intra_freq_data.residue1 == row['residue1']) & (new_intra_freq_data.residue2 == row['residue2'])].shape[0] == 0:\n",
    "                    new_intra_freq_data = new_intra_freq_data.append({'residue1':row['residue1'],'residue2':row['residue2'],'contact_freq':row['contact_freq']/len(traj_notes)},ignore_index=True)\n",
    "                else:\n",
    "                    new_intra_freq_data.loc[(new_intra_freq_data.residue1 == row['residue1']) & (new_intra_freq_data.residue2 == row['residue2']),'contact_freq'] += row['contact_freq']/len(traj_notes)\n",
    "        with open('/home/scottzhuang/pdc/'+ traj_notes[0] +'/getcontact/'+ traj_notes[0] +'.'+ interaction +'.freq.intra.resid.rep_avg.tsv', 'w') as output_file:\n",
    "            output_file.write(open('/home/scottzhuang/pdc/'+ traj_notes[0] +'/getcontact/'+ traj_notes[0] +'.'+ interaction +'.freq.intra.tsv').readlines()[0])\n",
    "            output_file.write(open('/home/scottzhuang/pdc/'+ traj_notes[0] +'/getcontact/'+ traj_notes[0] +'.'+ interaction +'.freq.intra.tsv').readlines()[1])\n",
    "            for index,(res1, res2, frequency) in new_intra_freq_data[['residue1','residue2','contact_freq']].iterrows():\n",
    "                output_file.write('\\t'.join([res1, res2, \"%.3f\" % frequency]) + \"\\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "Parallel(n_jobs=num_cores)(delayed(make_freq_resid_rep_avg)(traj_notes) for traj_notes in traj_notess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepchem",
   "language": "python",
   "name": "deepchem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
